<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[关于项目中线程池治理的实践]]></title>
    <url>%2F%E5%85%B3%E4%BA%8E%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%B2%BB%E7%90%86%E7%9A%84%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[前言实际项目中使用线程池的场景往往很多，比如批量刷数据，批量获取数据等用来提升接口或代码运行速度，亦或是通过提交异步任务来让某些不是特别需要实效性的任务异步执行，减少当前主线程的运行时间，而jdk也给我们提供了Executors类来支持我们很方便的创建和使用线程池，spring也封装了线程池加强使用体验。 但是在项目中，我们更多的是能看到各式各样的线程池使用情况，有自己创造的，也有直接使用公共的（例如CompletableFuture），这些在使用上完全没有问题，但是有如下几个弊端： 1.线程池容易在配置上踩坑，比如线程池的队列打满后，才会触发线程池新创建线程，如果使用的是无界队列，那么其实最大线程数的参数（maximumSize）就失效了 2.部分版本的线程池有bug，比如java8中的Executors.newSingleThreadExecutor()就会出现提前GC被关闭的问题（详见这里），而代码中大家经常又会复制粘贴某些代码，就导致有问题的代码会污染项目 3.在项目变得庞大起来后，过多的线程池，导致线程数量剧增，频繁切换线程导致对系统资源的消耗，其实过多的线程并不能够带来更多的性能上的提升，cpu一共就固定的几个核心，也就是说他最多并行执行的线程也就是固定的数量，而且除开项目中我们可以把控的线程数之外，第三方依赖和系统进程都会有线程使用cpu，所以对于线程数的设计，需要针对项目去分析 4.往往不知道如何配置线程池的参数，也往往不知道线程池的利用率是怎么样的，上线后不知道效果如何 5.线程池往往没法直接继承父线程的上下文，对于需要使用traceId等跟踪的情况下，会比较麻烦 我们需要提出一个解决方案，来解决上述的问题，在我们公司实际项目探索中，发现我们使用线程池的方式多种多样，如下图 解决方案大家很多都是自己拍脑子定的线程池参数，或者为了使用方便，使用了jdk的静态方法，也有一些是直接复制的别人的代码。经过分析，我们使用线程池的业务主要可以分为三类，第一类是非实效性的业务，比如发短信或者向其他系统同步数据等，不要求实时完成的业务，第二类是实效性的业务，比如批量刷数据批量拉数据等，是为了加快处理性能加快接口响应速度，第三类是专用线程池，针对特别的需求使用的 所以根据以上三类，我们设计了一个工具类，将大家使用线程池的方式收敛，实效性和非实效性统一成两个全局的线程池，配置上作区分，所有相关的业务统一使用这个工具类代替创建新的线程池，而专用线程池则根据业务继续保持专用的线程池，这样减少线程池的随意创建和使用在两个全局线程池的配置上，将非实效性的线程池总线程数设置成小于实效性线程池的线程数，这样做的目的是为了提高非实效性线程排队的概率，从而增加cpu执行实效性线程的几率。而对于线程池具体执行的效果上，我们选择了第三方的动态线程池，可以动态调整参数，实时报警和实时监控。最终我们封装了一个具有动态调整参数，自动继承traceId，可以实时监控的线程池工具类综上，线程池的治理完毕，在规范了异步任务代码书写的情况下，也尽量避免了资源浪费，做到了统一。]]></content>
      <categories>
        <category>实践</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我们公司为什么从Mysql切换成TibDB]]></title>
    <url>%2F%E6%88%91%E4%BB%AC%E5%85%AC%E5%8F%B8%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BB%8EMysql%E5%88%87%E6%8D%A2%E6%88%90TibDB%2F</url>
    <content type="text"><![CDATA[我们为什么要换TiDB在业务增长的情况下，伴随的是数据量的剧增，在传统Mysql的服务体系下，千万甚至上亿的数据对于数据存储和查询来说，似乎只有通过增加Mysql实例 ,分库分表等措施来应对，通常这些操作对于研发和运维来说都是很痛苦的，并且在做数据同步时更是需要小心翼翼 但此时另一端的TiDB应运而生,他的优点在于：1.天生就是分布式的数据库，可以无限扩展，不用在考虑分库分表2.对于大数据友好，支持Spark对主库进行实时查询3.可以做到故障自动恢复4.从Mysql切换至TiDB的成本对于研发来说非常小，TiDB支持Mysql的语法（比较严格，某些Mysql的特别语法TiDB并不会通过），并且使用kv结构模拟了关系型结构 TiDB的架构是怎样的 对于Mysql来说，架构基本可以分为server层和engine层，server层负责连接、sql解析等，engine层负责数据存储，当Mysql要进行扩展时，传统的扩展方案,是对其进行多节点部署，也就是说多一个节点，就会多一套server和engine，看起来很重对不对 而对于TiDB来说，他把整体架构拆的更细，TiDB server等于Mysql的server层，TiKV server等于Mysql的engine层，而PD server则是TiDB的元数据管理层，是相对语Mysql来说新加的一个层，我理解其实跟Redis的sentinel差不多，在TiDB需要扩展时，可以根据具体的业务情况进行扩展，当计算能力/处理sql的能力到达瓶颈时，可以增加TiDB server节点数量扩展计算能力，当存储出现瓶颈时可以通过增加TiKV server来扩展存储能力，这样以来就变得轻盈又灵活 TiDB是怎么存储数据的TiDB的存储在于TiKV，这个服务集群来存储数据，TiKV整体就是一个大型的kv存储结构，TiKV的底层是通过rocksdb来进行数据存储，这个存储引擎可以高效的利用SSD TiKV里面有一个重要的概念，region，可以理解为是一段连续的key组成的数据段，这是TiDB里面数据传输和同步的最小数据单元，所有的数据会被划分成n个region，然后由PD server来尽可能平均的分配到不同TiKV节点上 当然每个TiKV节点上的数据也会有备份在其他节点上，这样不会在节点挂掉的时候导致数据丢失，TiKV之间在相互数据备份的时候也是通过region为单位备份的，每个region都会有备份在不同的节点中，原理是不同节点之间相同的region，会构成一个raft group，其中会有一个leader来对其他follower传输数据，当leader挂掉后，各个节点之间会通过raft选举出一个leader，保证数据安全]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>TiDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github pages + gitalk自动化部署与初始化]]></title>
    <url>%2Fgithub-pages-gitalk%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[要达到的效果github pages是一个github提供的一种免费的静态页面管理服务，可以把页面托管给github并自动分配一个域名，也可以配置自定义的域名给这个页面管理服务博客源码方面我使用的是hexo + next theme的一套组合，我们现在想要达到的效果是当hexo的页面源码推送完成后，让github自动帮我们编译页面文件，并且推送至仓库，然后部署静态页面服务，最后初始化文章gitalk评论区 总体流程是源码仓库收到推送，触发github actions脚本执行，首先检出代码，安装hexo环境，触发hexo deploy推送编译好的页面至页面仓库，页面收到推送后会自动触发github pages的部署脚本，进行网页部署，与此同时，源码仓库的第二部分python脚本开始运行，拉取源码中sitemap部分，获取最新的文章调用github api在文章仓库创建issue 关于仓库配置关于这块源码的话，我会在账号底下新建一个私有化仓库，用来保存源码和配置，hexo编译好的页面我会放置在另一个公开的仓库，并配置github pages服务，里面仅仅包含编译好的页面以及对应文章的issue（也就是文章评论区），过去我是用hexo deploy命令进行仓库部署，现在这块会放到自动化里去做，我们后面去讲 关于源码中SEO、域名解析、以及readme部分hexo deploy命令在将项目推送至仓库的时候，是会全量把编译好的项目覆盖推送至仓库，所以需要注意以下几点通常不同搜索引擎会提供不同的SEO验证方式，如果你使用的是文件验证方式，那么你需要把你的验证文件放到源码根目录的的source文件夹下，这样会让搜索引擎在定期搜索的时候不会将你的网站标记为失效网站对于域名解析，github pages采用CNAME进行域名解析，所以你项目的根目录（也就是源码中的source文件夹）中需要包含一个CNAME的文件提供给github去读取，否则的话部署完项目github就不会认识你的自定义域名，你又需要重新配置一遍了一般来讲readme文件都是md格式的，如果你不想被hexo把这个md文件编译成html，那么你就需要在hexo的配置文件_config.yml中添加skip_render: README.md即可 关于自动化的原理和配置自动化的原理就是利用github仓库提供的actions的功能来实现的，他有点类似jenkins，可以写一段脚本来指定某个动作配置方面我们通过私有化的源码仓库进行创建，在源码中的根目录创建.github/workflows/depoly_hexo.yml这一串文件夹和文件，github actions会读取并执行这个脚本这个脚本上半部分是使用hexo进行编译和推送，下半部分是触发一段python脚本来进行issue初始化直接上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# This workflow will install Python dependencies, run tests and lint with a variety of Python versions# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actionsname: Deploy Hexo and create issue#指定触发类型，这里是master分支被push的时候on: push: branches: [ master ]jobs: build-hexo: runs-on: ubuntu-latest strategy: fail-fast: false matrix: python-version: [ "3.8" ] steps: #检出代码 - name: Checkout uses: actions/checkout@v3 with: submodules: true # Checkout private submodules(themes or something else). #配置并使用hexo编译和部署仓库 # Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.) - name: Cache node modules uses: actions/cache@v1 id: cache with: path: node_modules key: $&#123;&#123; runner.os &#125;&#125;-node-$&#123;&#123; hashFiles('/package-lock.json') &#125;&#125; restore-keys: | $&#123;&#123; runner.os &#125;&#125;-node- - name: Install Dependencies if: steps.cache.outputs.cache-hit != 'true' run: npm ci # Deploy hexo blog website. - name: Deploy id: deploy uses: sma11black/hexo-action@v1.0.3 with: deploy_key: $&#123;&#123; secrets.HEXO_DEPLOY_KEY &#125;&#125; user_name: your name # (or delete this input setting to use bot account) user_email: your email # (or delete this input setting to use bot account) commit_msg: deploy something # (or delete this input setting to use hexo default settings) # Use the output from the `deploy` step(use for test action) - name: Get the output run: | echo "$&#123;&#123; steps.deploy.outputs.notify &#125;&#125;" #使用python脚本初始化issue - name: Set up Python $&#123;&#123; matrix.python-version &#125;&#125; uses: actions/setup-python@v3 with: python-version: $&#123;&#123; matrix.python-version &#125;&#125; - name: Install dependencies run: | python -m pip install --upgrade pip if [ -f requirements.txt ]; then pip install -r requirements.txt; fi - name: Create issue env: GITHUB_TOKEN: $&#123;&#123; secrets.ACCESS_TOKEN &#125;&#125; run: | python create_issue.py 接下来是python的脚本，用来初始化issue，这个要放在项目的根目录，另外还有个要求是需要你的网站配置过sitemap1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from urllib.parse import unquoteimport requests,jsonimport hashlib,osimport reapi_user='maxisvest' #github用户名api_token=os.environ.get('GITHUB_TOKEN') #申请的github访问口令session=requests.session()repo='blog' #存储issue的repowith open("./public/sitemap.xml") as f: content = f.read() r = re.compile(r'(https://blog.maxisvest.com.*)') all_entrys=re.findall(r,content)def md5(s): hash = hashlib.md5() hash.update(s.encode('utf8')) return hash.hexdigest()headers = &#123; "Authorization" : "token &#123;&#125;".format(api_token), "Accept": "application/vnd.github.v3+json"&#125;for i in range(len(all_entrys)): _url=all_entrys[i] _title = _url[27:] _title = _title[:-7] if _title.endswith('html') or _title.endswith('htm'): continue label_id=md5('/' + _title + '/') _title = unquote(_title) data = &#123; "title": _title+' | Maxisvest的博客', "labels": ['Gitalk',label_id], "body": _url &#125; _get_issue=session.get(url='https://api.github.com/repos/&#123;&#125;/&#123;&#125;/issues?labels=Gitalk,&#123;&#125;'.format(api_user,repo,label_id),verify=False) if not _get_issue.json(): print(f'post 《 &#123;_title&#125; 》是新发布的文章，开始创建issue！') _result=session.post(url='https://api.github.com/repos/&#123;&#125;/&#123;&#125;/issues'.format(api_user,repo),headers=headers,data=json.dumps(data),verify=False) if _result.status_code==201: print(f'post 《 &#123;_title&#125; 》create issue success !') else: print(f'post 《 &#123;_title&#125; 》create issue failed!!!,reson: &#123;_result.text&#125;') continue print(f'post 《 &#123;_title&#125; 》是旧文章')session.close()]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>hexo, gitalk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于我的博客从腾讯云迁移至github以及评论插件valine切换到gitalk的一些琐事]]></title>
    <url>%2F%E5%85%B3%E4%BA%8E%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%E4%BB%8E%E8%85%BE%E8%AE%AF%E4%BA%91%E8%BF%81%E7%A7%BB%E8%87%B3github%E4%BB%A5%E5%8F%8A%E8%AF%84%E8%AE%BA%E6%8F%92%E4%BB%B6valine%E5%88%87%E6%8D%A2%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%90%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[为什么不用腾讯云而换github了？最初最初有搭建博客的想法时，是采用腾讯coding的服务，代码和静态页面服务coding pages都在同一个仓库，那会是通过hexo老三套命令进行渲染和发布页面，然后按照教程将自己的域名解析到coding服务上，就可以实现页面访问了后来coding的业务似乎一直在进行变化，曾经做好的配置直接失效，需要按照coding提供的最新教程重新做配置，而且却来越复杂，到今年，腾讯直接把coding的服务入口下线了，之前的服务还是保留，但是就是没法通过coding的静态页面入口进行配置了（当然可以花钱购买他们新的静态页面服务）所以我决定迁移到更加灵活的github上，利用github的pages功能，代码放在私有仓库，hexo deploy的页面放在公共仓库，这样可以防止敏感数据泄漏，还可以利用到gitHub的actions工作流进行自动部署，可以说是很方便了，而且github绑定自定义域名不需要购买会员（没错，说的就是你，gitee），也不需要做认证和备案（个人觉得很爽），唯一一个不好就是服务器在境外，可能会受网络影响 为什么要切换评论插件valine到gitalk？最开始是通过valine + leancloud进行博客文章的评论功能，但是leancloud十分不稳定，最近直接域名无法解析，导致博客评论无法展示所以本着简洁省事的原则，找了个更古老的方案，就是使用gitalk，美观又优雅，但是需要登陆github账号才可以评论，而且发表文章后需要手动进行评论初始化才能进行评论其实gitalk的原理就是在仓库里面建issue，gitalk通过把文章标题进行md5编码，然后通过github的api创建一个issue并给他加上这个md5编码的tag，通过一个md5编码和Gitalk的tag来关联到一篇文章上，issue下面的评论会被gitalk展示到评论区当然也不是必须要手动初始化，也可以把初始化的功能做到github actions的脚本里，当静态页面部署完，就跑一遍自动创建issue的脚本，做到真正的自动化，之后出一篇文章说一下自动化的相关内容，可以做到文章推送到master后，自动渲染页面并推送部署github pages，自动初始化新文章的评论区的效果]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一种可以整合spring IoC机制的可插拔部署的技术思路]]></title>
    <url>%2F%E4%B8%80%E7%A7%8D%E5%8F%AF%E4%BB%A5%E6%95%B4%E5%90%88spring-IoC%E6%9C%BA%E5%88%B6%E7%9A%84%E5%8F%AF%E6%8F%92%E6%8B%94%E9%83%A8%E7%BD%B2%E7%9A%84%E6%8A%80%E6%9C%AF%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[问题对于一些需要在多方部署，代码大部分相同，但是只有部分逻辑或者业务不同的系统(比如一些管理系统需要根据当地法规或者标书中的要求去做一些改动适配)，在以往实践中，基本会有两种管理方式1.创建多个项目，其中会有冗余代码2.在单个项目中，编写多个核心逻辑，部署时，在配置文件选择走哪个逻辑对于这两种方案来说，都会产生冗余的代码，可扩展性和管理性都会受限，牵一发可能会动全身 思路目前基于spring提供的可扩展接口来说，有一种实现方式可以比较好的来规避这些问题核心的思路是只有一个框架服务，而核心代码从中拆出来当做jar包，在部署时当做plugin加载到JVM中，并且jar包中的代码可以和spring的IoC容器整合为什么会要整合IoC容器？整合后在框架部分只需要使用@Resource注解注入由IoC管理的jar包内的bean即可使用可插拔的服务，这样可以方便开发人员去编写代码，也可以在无需修改框架代码的情况下去变更接口的实现 具体实现spring在启动过程中提供了多种可扩展的点，我们这次要利用的是BeanDefinitionRegistryPostProcessor、ImportBeanDefinitionRegistrar以及ClassPathBeanDefinitionScannerspring在启动时，会先扫描classpath下面的所有符合条件的class，并且生成这些class的描述(beanDefinition)，这些beanDefinition被统一管理在一个ConfigurableListableBeanFactory的工厂里，在制作完所有beanDefinition后，会逐一去实例化并且注入相关的属性这次瞄准的就是这个过程，在实例化前，将我们扩展jar包内的bean扫描进ConfigurableListableBeanFactory工厂里启动时，spring会提前实例化一些类，比如处理beanDefinition的这些类，所以我们需要将自己的BeanDefinitionRegistryPostProcessor加入到spring容器中，可以在启动类中加入@Configuration和@Import来告诉spring去加载我们的BeanDefinitionRegistryPostProcessor然后需要定义一个类扫描机制，因为spring默认的扫描机制只会扫描classpath下面的类，而我们的jar包并不属于classpath，所以我们需要继承ClassPathBeanDefinitionScanner来重写doScan方法，提取出ClassLoader并将jar包的路径填入，让ClassLoader加载这个jar包下的class，等于加载到了classpath下面在定义我们自己的BeanDefinitionRegistryPostProcessor时需要告诉spring要将哪些类加入到spring IoC容器中至此基本可以完成功能]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全链路日志追踪方案及MDC代码分析]]></title>
    <url>%2F%E5%85%A8%E9%93%BE%E8%B7%AF%E6%97%A5%E5%BF%97%E8%BF%BD%E8%B8%AA%E6%96%B9%E6%A1%88%E5%8F%8A%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在分布式服务中追踪一次请求的日志是一件非常重要的事，本文提供一种利用logBack + log4j的方案来解决这个问题最终要实现的目的是通过一个traceId，然后再ELK中找到这个traceId对应请求所有打印的日志来，一步一步看 1.设计思路多个系统服务同时需要依赖一套生成和读取traceId的方案，所以，我们首先需要搞一套依赖，用来管理traceId不同服务引用后，当一个请求进入服务中，服务首先检测他有没有携带traceId，没有的话将traceId补上，并放入MDC中，该请求进入下一个服务时，将traceId携带各个服务间打印日志使用统一的工具类进行打印，打印中从MDC中取出traceId并打印，然后由ELK搜集整理 2.生成和读取traceId的方案生成traceId可以使用UUID来做全局唯一标识生成的traceId放入MDC中，用来给所有打印日志的地方使用12345678910111213141516/** * 获取traceId */public static String getTraceId() &#123; //获取 String traceId = MDC.get(TRACE_ID); //如果traceId为空，则返回默认值 return StringUtils.isBlank(traceId) ? DEFAULT_TRACE_ID : traceId;&#125;/** * 生成traceId */public static String gentraceId() &#123; return UUID.randomUUID().toString().replaceAll(&quot;-&quot;,&quot;&quot;);&#125; 3.何时将traceId记录到请求中在服务中定义WebFilter，读取到request后检查是否携带traceId，未携带代表该服务是这个请求的入口服务，需要将traceId设置到请求中已携带代表是从上游服务下来的请求，直接使用该traceId来进行打印这里我们需要用到一个工具叫MDC，他提供了静态方法可以用来做线程间隔离的数据存储，底层是封装了一套threadLocal，这个会在接下来分析12345678910111213141516171819202122232425262728293031@WebFilter(urlPatterns = &quot;/*&quot;, filterName = &quot;traceIdFilter&quot;)@Order(1)public class Filter0_traceIdFilter extends GenericFilterBean &#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; logger.info(&quot;traceIdFilter before&quot;); //traceId初始化 initTraceId((HttpServletRequest) servletRequest); //执行后续过滤器 filterChain.doFilter(servletRequest,servletResponse); logger.info(&quot;traceIdFilter after&quot;); &#125; /** * traceId初始化 */ private void initTraceId(HttpServletRequest request) &#123; //尝试获取http请求中的traceId String traceId = request.getParameter(&quot;traceId&quot;); //如果当前traceId为空或者为默认traceId，则生成新的traceId if (StringUtils.isBlank(traceId) || traceIdUtil.defaultTraceId(traceId))&#123; traceId = traceIdUtil.gentraceId(); &#125; //设置traceId traceIdUtil.setTraceId(traceId); &#125;&#125; bounce.MDC分析MDC提供了threadLocal的封装，但封装并不存在于MDC这个类中，而是存在于MDCAdapterMDCAdapter是一个接口，像logback就提供了一个实现，叫做LogbackMDCAdapter在MDC初始化中，会先去寻找是否有实现，没有MDCAdapter的实现的话会用默认的NOPMDCAdapter来做实现，其实就是什么也没做 MDCAdapter提供了get(),put(),remove(),clear(),getCopyOfContextMap(),setContextMap()方法在LogbackMDCAdapter中，分别对这些方法进行了实现，其实很简单，就是一些增删改查 在LogbackMDCAdapter里定义了两个常量WRITE_OPERATION, MAP_COPY_OPERATION，并且有一个threadLocal来记录上一次的操作类型，在增删中会将操作类型设置为WRITE_OPERATION，在获取keys的方法中将操作类型记为MAP_COPY_OPERATION，作者的意图是用这个操作来判断一次的操作类型，如果是拿全量map（getPropertyMap()方法）则要保持被拿走的map是不变的，新的写操作需要写到新map里按照代码的逻辑，写操作(put(),remove())都会去判断是不是该把值写到新的map里，判断的依据上一次操作是不是MAP_COPY_OPERATION，也就是是不是有人拿走了map，如果有人拿走了map就要写到新map里，没有的话就继续写到旧map中 4.怎么打印日志打印工具类需要将traceId打印到日志中，利用filter中的向MDC中存储的traceId，来进行打印MDC的线程隔离性保证了同一个线程在代码的不同位置拿到的数据都一致123//打印你要的内容String traceId = MDC.get(TRACE_ID);log.info(traceId + xxx); 5.在ELK中查询可以通过日志中打印的关键字或者其他一些信息定位到某一段日志代码，找到traceId并在ELK中搜索，就可以检索到所有这个请求下的日志 6.如果有需要的话。。。使用这种方式既简单又高效的完成了日志打印，但是不是还少了些什么？比如接口的时间统计？调用方？这些都是可以提高问题查询效率的一个方式，也是可以增加在ELK中的检索类别，可以更快的帮助你定位到需要的日志下面可以提供一种方式，利用切面切所有的controller，从切点用取出需要的数据，然后进行打印，但是别忘了要在保证性能和安全性的角度下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140@Aspect@Component@Slf4jpublic class SysLogAspect &#123; @Pointcut(&quot;bean(*Controller)&quot;) public void logPointCutRestController() &#123; &#125; /** * RestController切面 * @param joinPoint * @return * @throws Throwable */ @Around(&quot;logPointCutRestController()&quot;) public Object restControllerAspect(ProceedingJoinPoint joinPoint) throws Throwable &#123; return aroundInternal(joinPoint); &#125; public Object aroundInternal(ProceedingJoinPoint joinPoint) throws Throwable &#123; HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); long beginTime = System.currentTimeMillis(); //返回值 Object returnValue = null; String param = &quot;&quot;; String apiName = &quot;&quot;; String className = &quot;&quot;; String methodName = &quot;&quot;; String functionName = &quot;&quot;; long time = 0; String status = &quot;&quot;; String code = &quot;&quot;; String message = &quot;&quot;; try &#123; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); //只打印注解为RequestMapping类并且没有IgnoreSysLog注解的方法 boolean needLog = false; Annotation[] annotations = method.getAnnotations(); if (Objects.nonNull(annotations)) &#123; boolean hasMappingAnnotation = Arrays.stream(annotations) .anyMatch(annotation -&gt; ( annotation instanceof RequestMapping || annotation instanceof GetMapping || annotation instanceof PostMapping)); boolean hasIgnoreSysLogAnnotation = Arrays.stream(annotations) .anyMatch(annotation -&gt; (annotation instanceof IgnoreSysLog)); //是mapping并且没有IgnoreSysLog注解，需要打印 needLog = hasMappingAnnotation &amp;&amp; (!hasIgnoreSysLogAnnotation); &#125; if (!needLog) &#123; return joinPoint.proceed(); &#125; //请求的 类名、方法名 className = joinPoint.getTarget().getClass().getName(); String simpleName = joinPoint.getTarget().getClass().getSimpleName(); methodName = signature.getName(); SysLog sysLog = method.getAnnotation(SysLog.class); if (sysLog != null) &#123; //注解上的描述 apiName = sysLog.value(); &#125; functionName = simpleName + &quot;:&quot; + methodName; //请求的参数 Object[] args = joinPoint.getArgs(); String[] paramNames = signature.getParameterNames(); Map paramMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; args.length; i++) &#123; if (!(args[i] instanceof HttpServletRequest)) &#123; //支持文件上传 if (args[i] instanceof MultipartFile[]) &#123; MultipartFile[] files = (MultipartFile[]) args[i]; List&lt;String&gt; fileInfos = new ArrayList&lt;&gt;(); for (MultipartFile file : files) &#123; String nameFiled = file.getName(); String fileName = file.getOriginalFilename(); long kByte = file.getSize() / 1000; fileInfos.add(&quot;[&quot; + nameFiled + &quot;:&quot; + fileName + &quot;, size=&quot; + kByte + &quot;kb]&quot;); &#125; paramMap.put(paramNames[i], String.join(&quot;,&quot;, fileInfos)); &#125; else &#123; paramMap.put(paramNames[i], args[i]); &#125; &#125; &#125; param = JacksonUtil.toJsonString(paramMap); &#125; catch (Exception e) &#123; //吞掉业务异常以外的异常，不影响业务正常进行 log.warn(&quot;SysLogAspect.around Exception:&quot;,e); &#125; try &#123; //连接点：被切的方法的代码还会继续执行，所以当业务代码出现异常的时候会抛到这里来，此异常不能自己消化，需要继续往外抛。 returnValue = joinPoint.proceed(); &#125; catch (Exception e) &#123; status = String.valueOf(ComResponse.ERROR_STATUS); if (e instanceof BizException) &#123; code = String.valueOf(((BizException) e).getCode()); message = ((BizException) e).getMsg(); &#125; else if (e instanceof RemoteAccessException) &#123; code = String.valueOf(((RemoteAccessException) e).getCode()); message = ((RemoteAccessException) e).getMsg(); &#125; else &#123; code = String.valueOf(ResponseCodeEnums.SYSTEM_ERROR_CODE.getCode()); message = JacksonUtil.toJsonString(e); &#125; time = System.currentTimeMillis() - beginTime; log.error(xxx); //业务异常需要继续往外抛出，抛给统一异常处理器处理异常。否则当业务发生异常了，异常信息都会被吞掉。 throw e; &#125; try &#123; //接口耗时 time = System.currentTimeMillis() - beginTime; //从接口返回值判断接口调用状态 if (Objects.nonNull(returnValue)) &#123; //伪代码 &#125; log.info(xxx); &#125; catch (Exception e) &#123; status = String.valueOf(ComResponse.ERROR_STATUS); code = String.valueOf(ResponseCodeEnums.SYSTEM_ERROR_CODE.getCode()); message = JacksonUtil.toJsonString(e); //当try里面的代码快出现异常，需要自己把异常消化掉不然会影响业务的正常进行。 log.error(xxx); &#125; return returnValue; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用netatalk打造一款属于自己的Time-Machine在线备份服务器]]></title>
    <url>%2F%E4%BD%BF%E7%94%A8netatalk%E6%89%93%E9%80%A0%E4%B8%80%E6%AC%BE%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84Time-Machine%E5%9C%A8%E7%BA%BF%E5%A4%87%E4%BB%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言MAC系统的Time Machine功能曾经拯救过我电脑几次，对于我这种爱折腾的人来说十分有用但是麻烦的点在于每次需要手动备份，需要插上移动硬盘来进行备份，就很不方便，有时会忘掉其实MAC是可以在合适的网络硬盘上进行备份的，比如部分NAS，群辉等，但是都太贵了，于是我自己买了一套路由器大小的微型服务器，配置了一块2T硬盘，配置比较一般，但是作为服务器来说够用了，之后就可以安装centos系统并且安装netatalk和avahi来让mac备份到这台服务器上 1.下载centos7的镜像，将该镜像刻录至U盘12345678910#命令确定U盘的路径diskutil list #卸载U盘（这里/dev/disk2是查到的U盘路径，一定要确认对）diskutil unmountDisk /dev/disk2 #安装pv工具brew install pv#可视化刻录进度并刻录镜像pv -cN source &lt; 镜像路径 | sudo dd of=/dev/rdisk2 bs=4m## 显示下面进度source: 5.2GiB 5:11:41 [ 503KiB/s] [=====================&gt; ] 71% ETA 2:01:56 2.安装centos73.连接网络可以选择网线直连或者wifi连接，我这里使用的是wifi连接因为我的无线网卡为高通QCA9377，似乎属于旧版网卡，所以进入系统后打开终端，输入123cd lib/firmware/ath10k/QCA9377/hw1.0/sudo mv firmware-6.bin ~sudo mv notice_ath10k_firmware-6.txt ~ 来移除不兼容的wifi驱动，留下firmware-5.bin和notice_ath10k_firmware-5.txt即可这样就可以使用wifi了 4.安装netatalk和avahi123456789101112#安装编译所以依赖yum install gcc makeyum install libgcrypt-devel libdb-devel#开始准备编译和安装cd &quot;你新建的文件夹&quot;wget http://sourceforge.net/projects/netatalk/files/netatalk/3.1.12/netatalk-3.1.12.tar.gztar zvxf netatalk-3.1.12.tar.gzcd netatalk-3.1.12./configure --with-init-style=redhat-systemd makemake install 安装后在某个位置新建文件夹当做备份文件夹，按如下配置编辑配置文件vi /usr/local/etc/afp.conf1234[TimeMachine] path=你的备份文件夹 time machine=yes vol size limit = 500000 #这是限制500GB 5.安装avahi用于网络发现安装avahiyum install avahi然后增加配置文件 vi /etc/avahi/services/afpd.service，如果没有的话就新建一个1234567891011121314&lt;?xml version=&quot;1.0&quot; standalone=&apos;no&apos;?&gt; &lt;!DOCTYPE service-group SYSTEM &quot;avahi-service.dtd&quot;&gt; &lt;service-group&gt; &lt;name replace-wildcards=&quot;yes&quot;&gt;%h&lt;/name&gt; &lt;service&gt; &lt;type&gt;_afpovertcp._tcp&lt;/type&gt; &lt;port&gt;548&lt;/port&gt; &lt;/service&gt; &lt;service&gt; &lt;type&gt;_device-info._tcp&lt;/type&gt; &lt;port&gt;0&lt;/port&gt; &lt;txt-record&gt;model=TimeCapsule&lt;/txt-record&gt; &lt;/service&gt; &lt;/service-group&gt; 6.设置开机启动启动程序并设置开机启动systemctl start avahi-daemonsystemctl start netatalksystemctl enable avahi-daemonsystemctl enable netatalk关闭防火墙或者开放 548 端口，否则可能无法连接到netatalk暴露的端口 7.MAC端配置打开mac的finder，command + k，连接到你的服务器的ip，并输入服务器的用户名密码 afp://192.168.1.X 在系统设置中将加载的网络服务器设置为备份硬盘即可 之后使用过程中，MAC会自动寻找局域网内由avahi广播的机器，自动加载添加过的网络硬盘并备份 8.恢复文件或恢复系统恢复文件点击时间机器图标并点击进入时间机器，稍等会便会加载出网络上的时间机器的备份内容，右键某个时间的你想恢复的文件，选择恢复至即可 恢复系统如果你的MAC挂了，可以通过如下方式全盘恢复你的MAC到一个时间点 开机按住command + R 进入恢复模式选择时间机器恢复点击选择网络服务器输入 afp://用户名:密码@IP地址/网络备份磁盘名例如 我服务器IP为192.168.50.74，网络备份磁盘名 TIME MACHINE ONLINE，其中的空格需要转义afp://yu:password@192.168.50.74/TIME%20MACHINE%20ONLINE回车添加即可然后选择对应的恢复备份即可恢复]]></content>
      <categories>
        <category>mac</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[camunda流程引擎简明教程]]></title>
    <url>%2Fcamunda%E5%BC%95%E6%93%8E%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[前言公司项目中使用到了camunda引擎，这个技术框架在国内的文章还是比较少，于是自己在使用中先做一部分总结 首先上官网doc地址，目前已经更新到了7.13版本 https://docs.camunda.org/manual/7.13/如果学习使用可以搭配camunda modeler这个官方的应用，用来可视化的打开和编辑流程模型文件 一般来讲，流程引擎可以使用在像流程审批，请假，以及一些需要过程性的任务上，他可以提供一种可复用，简便以及易更改的特点，所以在有上述业务需求的场景下，可以考虑使用camunda 本文选用bpmn模型 概念camunda的起源是来自于activity，在activity开发中团队内出现了分歧，所以一部分人转移到一个新的项目中，就是camunda 在camunda中，我们首先需要定义一个流程模型，有开始节点和结束节点，中间可以增加用户任务（userTask），门（gateway）和监听器（listener）等等这个流程模型就叫做processDefinition（流程模型定义） 我们可以调用api，开始一段新的流程实例（processInstance），流程实例会经过流程模型上的每一个节点，生成对应的任务，通过自动或用户手动完成任务，使得流程实例流转到下一个节点 流程实例和用户任务都可以携带变量，这些变量可以区分为全局变量和本地变量以供我们在适当的时候读取，例如遇到监听器或者门，就可以通过变量决定做些事情或进入不同的分支 整个过程有点类似java中的线程，模型定义中的节点就是一个个的类或者一个个方法，开始节点是main方法，运行main方法开启线程，线程会经过不同的方法，最终完成调用 使用camunda modeler可以规划模型定义，像下图中 整合springbootcamunda可以整合到springboot中，他提供了一个springboot-stater的专用版本 部署流程模型在项目中，我们可以在resource目录下定义一个processes文件夹，里面可以放camunda modeler生成的模型文件，在应用启动的时候，会将该模型加载到数据库中当然除了这种静态的加载方式，我们也可以调用camunda-engine提供的api，在运行时按照要求生成对应的模型并部署这种方式可以运用在业务中实时的编辑流程，编辑完后保存，后端去解析然后生成流程模型 开始编码在程序中，我们可以使用@resouce注解来使得spring注入camunda相关的api对象，例如RuntimeService, RepositoryService, TaskService或者HistoryService1234RuntimeService 用来启动，停止，编辑运行中的实例变量RepositoryService 用来查找或操作部署的流程模型等TaskService 专门操作taskHistoryService 操作所有历史的内容，例如已经完成的流程实例或完成的task 需要注意的是一个流程实例或者任务，在运行中会同时出现在runtime和history两个表中，而结束后则会从runtime表中移除，所以我通常在查询时只查询history表 启动流程可以使用RuntimeService#startprocessInstanceById()或者其他的start方法来开启一段流程 camunda中的任务task的类型task有很多类型，比如脚本任务，用户任务等等，用户任务是一种需要手动完成的任务才能使得流程继续流转的任务，也是比较常用的任务，我们可以来说说他用户任务可以分为单一任务或批量任务，而批量任务又可以分为串行任务和并行任务一个任务的所有者叫做assignee，在单一任务中，只要制定一个具体的值到assignee中即可，流程流转到这里时会生成一个task的实例而批量任务则需要指定一个用户集合，放在collection中，使用element variable来标记一个用户，在assignee处使用element variable的变量，这有点像for循环的写法在批量任务中，camunda会生成多个任务实例，串行属性的多任务，会按照collection中的用户顺序，先生成一个，完成之后生成下一个，并行属性的多任务，会同时生成所有collection中的用户任务实例串行一般用在比如请假中的领导审批，并行一般用在领导通过后的抄送中 task中的监听器在task中可以使用listener，可以完成一些复杂的业务逻辑，比如某些情况下的任务自动通过，或者用户完成任务后发送业务通知消息等等task的listener可以在模型定义中写死listener的class全路径 也可以在项目中使用注解+表达式在运行时attach到对应的任务实例上，当然我比较推荐后者，这样会比较灵活，不会因为listener的位置变了而重新部署模型 总结camunda的文档写的还是相对完善，推荐多去阅读，另外camunda的官方社区也是相对活跃，一般问题都可以在上面搜的到]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>camunda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过arthas在运行时执行代码]]></title>
    <url>%2F%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87arthas%E5%9C%A8%E8%BF%90%E8%A1%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[写在前面公司内arthas已经打在了每个容器中，推荐切换到启动java程序的用户之后使用 java -jar arthas-boot.jar 命令启动 如果启动有问题，可以尝试如下命令现场下载jar包启动 curl -O https://alibaba.github.io/arthas/arthas-boot.jar java -jar arthas-boot.jar 更多使用方法详见arthas官方文档 https://alibaba.github.io/arthas/ 推荐一篇入门级的比较通俗的博文：https://www.cnblogs.com/theRhyme/p/10659265.html 里头是最基础常用的命令，如sc、sm命令等 用法从spring context里获取任意bean并调用其方法或查看成员变量启动arthas并attach到进程后，执行tt命令来记录RequestMappingHandlerAdapter#invokeHandlerMethod的请求 tt -t org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethod然后随便访问该项目的一个地址，触发invokeHandlerMethod，例如 wget http://10.0.0.23:8080/xxxserv 输出12345678$ watch com.example.demo.Test * &apos;params[0]@sss&apos;$ tt -t org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter invokeHandlerMethodPress Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 101 ms.INDEX TIMESTAMP COST(ms IS-RE IS-EX OBJECT CLASS METHOD) T P1000 2019-01-27 16:31 3.66744 true false 0x4465cf70 RequestMappingHandlerAda invokeHandlerMethod:54 pter 可以看到fragement的index为1000之后输入tt -i 1000 -w &#39;target.getApplicationContext().getBean(&quot;baseExamService&quot;).fingerPrint2NewestState&#39;就可以得到名为baseExamService这个bean了，之后可以像写代码一样继续调用方法或者查看成员变量的值 以上是最基本的监听某个函数的用法，其实tt命令还可以支持条件表达式，更精准地监听某个特定调用 tt命令的官方详细说明：https://alibaba.github.io/arthas/tt.html tt -i命令用于查看调用信息，最常用的是查看输入参数params、当前上下文target、返回参数returnObj，如下： tt -i $index -w &#39;params&#39; tt -i $index -w &#39;target&#39; tt -i $index -w &#39;returnObj&#39;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建一套简单的fabric网络]]></title>
    <url>%2F%E6%90%AD%E5%BB%BA%E4%B8%80%E5%A5%97%E7%AE%80%E5%8D%95%E7%9A%84fabric%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[公司最近需要搭建一套区块链项目进行数据存储，于是研究了下HyperLedger Fabric这个IBM开发的重量级区块链框架，这个著名的项目采用了可插拔式的模块，提供联盟链和私链的区块链解决方案 一.安装环境安装docker和docker-compose 首先安装go语言环境，其次配置GOPATH环境变量，例如配置到/Users/admin/go cd $GOPATH然后创建目录src/github.com/hyperledger/，注意必须是创建这样的目录然后从github上clone一下fabric的源码，切换到1.4.6分支进入scripts目录，运行bootstrap.sh，拉取所需镜像这样基本的环境变量就搭好了 进入到fabric目录下，使用make configtxgenmake cryptogen生成之后可能需要的工具configtxgen、cryptogen，会生成到/build/bin下 二.启动项目拉取我的https://github.com/maxisvest/fabric-java-sample项目(改造自某个大神的项目)，进入`src/main/test/fixture/sdkintegratio`，使用`fabric.sh up`启动所需容器（其实就是官方的java sdk下面的测试环境启动的脚本）之后运行main方法就可以安装，实例化，操作链码了 src下的org.example.SimpleAssetChaincode供编写链码时的实时编译，编写好后将该类下的代码粘贴到src/main/test/fixture/sdkintegration/javacc/sample1/src/main/java/org/example/SimpleAssetChaincode.java中，以供安装链码需要 首先使用main方法manager.installChainCode() + manager.instantiateChainCode()，安装并实例化链码。之后链码又做修改，需要提升版本号，然后使用manager.installChainCode() + manager.upgradeChaincode()来升级链码。 本项目是springboot的项目，可以使用Application启动项目，然后安装链码后可以通过controller查询和写入数据 三.遇到的坑代码中使用channel.joinPeer()和channel.addPeer()有区别，新new出来的某个名字的channel如果join过peer，再次join会报错，只能通过add来加入peer，但是如果没join过peer直接使用add，不知道会怎么样，还没尝试 参考文章https://www.jianshu.com/p/bfb081a96337 对于channel的一些坑http://melanx.com/2019/06/20/fabric%E5%90%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AE%B2%E8%A7%A3/ Fabric配置文件讲解https://www.cnblogs.com/aberic/ 这个人的教程很详细，给了我不少启发，包括搭建和代码编写https://blog.csdn.net/mx1222/article/details/87921286 手动停止并删除链码 关于chaincode的坑install chaincode会将chaincode的源码传入到peer节点上，此时chaincode不会生效instantiate 会实例化chaincode，首先会启动一个java-env的容器对chaincode打包，其次生成chaincode的容器并启动起来，安装chaincode需要每个peer节点都安装，实例化只需要一次 官方给的chaincode中无法正常打包，因为依赖的guava版本太低了，需要手动定义20.0版本到pom下面才能正常打包 可以参考https://github.com/hooj0/fabric-chaincode-javahttps://github.com/hooj0/fabric-sdk-java-commons 如果出现fabirc error authorizing update: error validating ReadSet: readset expected key [Group] /Channel/App可以先结束并删除镜像docker rmi -f $(docker ps -aq)然后清理悬空镜像docker volume prune 可能会用到的命令一条命令实现停用并删除容器docker stop $(docker ps -q) &amp; docker rm $(docker ps -aq)]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排查一次线上connect reset by peer的异常]]></title>
    <url>%2F%E6%8E%92%E6%9F%A5%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8Aconnect-reset-by-peer%E7%9A%84%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[公司业务系统中有一个功能是某个系统客户端要定时加载目标jar包到系统中实现功能的热扩展，线上出了一个很奇怪的异常，是jar包提供端出现了connect reset by peer，隔一段时间就会报异常并且业务功能并没有受到影响，但是毕竟是生产环境，一点错误都有可能造成损失，问题还是要看的啊 首先定位问题，该异常由jar包提供端抛出，jar删除后便不再抛出，由此基本可以缩小范围至客户端加载jar包代码，但是光看代码似乎并没有什么大的问题所以我需要看看服务端抛异常的时候究竟在干什么，这里就用到了tcpdump，用这个工具将服务端的tcp日志打印出来 服务端部署在docker容器中，首先使用nsenter将命名空间锁定到容器的pid123456//获取容器id/namedocker ps | grep xxx//获取PIDdocker inspect --format &quot;&#123;&#123;.State.Pid&#125;&#125;&quot; container_id/name使用nsenter切换网络命名空间nsenter -n -t pid 之后查找客户端所在的ip地址，也就是tcpdump中要用到的host信息，我们要锁定查找范围为服务端到客户端之间的所有连接 使用命令tcpdump host 你的host -w tcphistory.pcap如果没问题的话，那么这个进程将持续把tcp的日志写入到tcphistory.pcap文件中 现在开始等待服务端日志抛出connect reset by peer异常，抛出后使用ctrl+c结束tcpdump命令 之后我们打开tcp日志分析的一个软件，叫做wireshark，我们惊奇的发现，抛出异常的时候有很多tcp连接在关闭了 客户端的tcp连接集中的发送reset包到服务端，于是我去了解了下在tcp什么情况下会发送reset包 123451.客户端尝试与服务器未对外提供服务的端口建立TCP连接，服务器将会直接向客户端发送reset报文。2.客户端和服务器的某一方在交互的过程中发生异常（如程序崩溃等），该方系统将向对端发送TCP reset报文，告之对方释放相关的TCP连接3.接收端收到TCP报文，但是发现该TCP的报文，并不在其已建立的TCP连接列表内，则其直接向对端发送reset报文4.在交互的双方中的某一方长期未收到来自对方的确认报文，则其在超出一定的重传次数或时间后，会主动向对端发送reset报文释放该TCP连接5.有些应用开发者在设计应用系统时，会利用reset报文快速释放已经完成数据交互的TCP连接，以提高业务交互的效率 用排除法，显然在我们的情境中是第二种情况 于是我去查找客户端的日志，似乎没有发现什么异常难道就这样结束了吗，不不不进入客户端容器利用名令netstat查看当前的的tcp连接，发现有一大票CLOSE_WAIT的TCP连接，说明服务端已经将数据写入完毕了，发送了FIN报文，但是好嘛，客户端不知道是什么在持有连接不放，让连接一直在等待结合tcpdump下来的日志，看起来是在客户端在集中释放资源，是跟什么有关系呢，我想到了GC于是我调出了客户端的gc日志，发现果然时间跟释放连接的时间有关系所以仔细搜寻了代码，发现在一个工具类中有使用HttpClient，每次发送请求都会创建一次Client的对象，使用完没有主动调用close()方法，似乎症结找到了做了一下优化，查阅资料发现4.x的HttpClient是线程安全的，可以作为静态的成员变量来复用，于是改造完成后测试 嗯，connect rest by peer依旧出现，但是好消息是CLOSE_WAIT消失了，连接数量似乎稳定了下来，解决了一个隐藏的问题，继续查 查到了下面一串代码12HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();long astModified = urlConnection.getLastModified(); 于是在本地尝试复现该问题1234HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection();long astModified = urlConnection.getLastModified();//强制关闭该连接urlConnection.disconnect(); 复现成功，经查阅资料，由于文件相对较大，方法getLastModified()方法中是去拿http请求头中的参数，所以，在tcp的第一个window中传输数据的数据就已经满足了程序，就没有继续读下面的流，于是在GC的时候urlConnection被关闭了，而服务器正在写入这个流，所以就出现了connect reset by peer，尝试如果是小文件，则第一个window就已经把所有数据都传输回来了，则不会出现connect reset by peer，tcp的window相当于一个缓冲区，缓冲区满了回去刷新，然后再次写入 所以将流消费完毕，即可解决问题1234InputStream inputStream = urlConnection.getInputStream();InputStreamReader inputStreamReader = new InputStreamReader(inputStream);BufferedReader bufferedReader = new BufferedReader(inputStreamReader);bufferedReader.lines().forEach(l -&gt; &#123;&#125;); 虽然不是很优雅，但是也是解决了问题 总结一下，这次排错发现了两个问题 4.x的HttpClient是线程安全的，并且是可复用的，如果没有复用，在调用完HttpClient时记得close掉这个对象，不然会出现连接占用的问题 HttpURLConnection如果不想让服务端出现异常，需要将流消费完毕，也就是让服务端把数据写完，才可以关闭这个连接]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一种简单的mysql数据压缩方案]]></title>
    <url>%2F%E4%B8%80%E7%A7%8D%E7%AE%80%E5%8D%95%E7%9A%84mysql%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[方案业务中某张表存储的数据量较大，导致磁盘飞速增长于是需要找到一种方案来减小线上数据库的占用量 业务使用的数据库为mysql数据库，InnoDB引擎故可以考虑使用InnoDB引擎自带的压缩方案 教程1.查询表原来所占的空间123select concat(round(sum(data_length/1024/1024),2),&apos;MB&apos;) as data from information_schema.tables where table_schema=&apos;数据库名&apos; AND table_name = &apos;表名&apos;; 2.设置压缩12SET GLOBAL innodb_file_per_table=1;SET GLOBAL innodb_file_format=Barracuda; 3.创建支持压缩的表或将已存在的表压缩12345-- 创建支持压缩的表CREATE TABLE 表名 (字段名 INT PRIMARY KEY,content varchar(255)) ROW_FORMAT=COMPRESSEDKEY_BLOCK_SIZE=8;-- 压缩已存在的表ALTER TABLE 表名 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8; 其中KEY_BLOCK_SIZE可以填写1，2，4等，数字越小压缩比例越高，但是读取的时候cpu也会相应的消耗变高 后记在测试环境，一张660mb的表被压缩到了85mb，压缩比例高到87%，耗时36s这是因为导致大量数据的字段保存着一个非常庞大的json，这个json中有非常多的相同的字符串压缩比例的高低有一部分原因是取决于被压缩的内容的重复程度]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>java 数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源线性规划器optaplanner]]></title>
    <url>%2F%E5%BC%80%E6%BA%90%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E5%99%A8optaplanner%2F</url>
    <content type="text"><![CDATA[前言optaplanner为一个开源的整数规划求解器，不仅可以计算N皇后等经典算法问题，还可以解决目前很多现实问题，例如： 最短路线 服务器负载 课表安排等等 其有着相对较快的求解速度以及多种约束编写方式。 软件更新速度相对较快并且文档丰富特别的perfect。 模型及约束基本设计流程1.基本流程设计一个结果载体及各种决策变量，开始计算前，我们先初始化所有决策变量及结果变量，计算时由解法器解法器根据规则具体决定填充到哪个将决策变量田中到结果中的哪个位置，例如在一个课表编排中，决策变量可以是时间，结果变量是一个课程，课程上边有空着的时间槽，用来填充时间，当计算完成时，时间也就被填充到了课表变量上，那么，我们就得到了一个课程具体上课的时间。 2.模型解法器要求使用@PlanningSolution标记的类来作为模型存放及各种变量的类，使用@PlanningEntity作为被计算的类，@PlanningEntity中需要解法器填充的变量来自于@PlanningSolution，也就是解法器中的 @ValueRangeProvider(id = &quot;times&quot;)和@ProblemFactCollectionProperty标记的变量提供者集合，而@PlanningEntity的变量需要通过@PlanningVariable(valueRangeProviderRefs = &quot;times&quot;)来指定需要采用哪个变量提供者 在初始化中，需要将@PlanningSolution中的所有变量初始化，@PlanningEntity中的三件套和其他基本属性初始化，变量无需初始化，这些变量将由解法器填充 有时候也可以在初始化的时候将变量也初始化到@PlanningEntity中，减少解法器的计算时间 @Score为解法器为结果打分的载体 3.约束文件约束文件有一种特殊的语言来编写，drl 科目的规则文件（约束）通过drl文件来编写，drl有特殊的语法，rule为具体的规则名称，when中为需要匹配的对象，then为匹配成功后需要执行的操作(在本模型中使用扣分的方式来约束最终的结果)，then内的代码为JAVA代码 当when的代码返回为true时，执行then内的代码，也就是说会对模型进行扣分，本排课模型采用Hard/Soft打分机制来打分（@PlanningSoluton中的@PlanningScore），当分数为0/0是为最佳结果，当分数为0/-10是也是可行解，分数为-1/-10时为不可行解 扣分类型为Hard还是Soft可以通过then内的代码控制，原则上将必须满足的条件归类为Hard约束，目标型的条件归类为Soft约束 1234567891011121314151617//同年级同班级的科目不在一块上rule &quot;basicConstraint&quot; when ClassSubjectEntity($id : id, $gradeInfo : gradeInfo , time != null, $time : time) ClassSubjectEntity(id != $id, gradeInfo.isSameGradeClass($gradeInfo), time == $time) then scoreHolder.addHardConstraintMatch(kcontext, -1);end//教师同一时间只上一节课rule &quot;basicConstraint2&quot; when ClassSubjectEntity($id : id, $teacherID : teacherID , time != null, $time : time) ClassSubjectEntity(id != $id, teacherID == $teacherID, time == $time) then scoreHolder.addHardConstraintMatch(kcontext, -1);end 当然，约束文件也可以利用JAVA代码实现，具体详见文档。 4.配置文件一个好的解法器当然离不开配置文件，optaplanner的配置文件细分的十分详细配置文件中可以指定计算所关联的类，约束的具体方式，每个计算步骤，计算步骤的具体规则，打分的方式和计算什么时候该停止等等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;//解法器的具体设置&lt;solver&gt; &lt;!--&lt;environmentMode&gt;FULL_ASSERT&lt;/environmentMode&gt;--&gt;&lt;!-- To slowly prove there are no bugs in this code --&gt; &lt;!--&lt;moveThreadCount&gt;AUTO&lt;/moveThreadCount&gt;--&gt;&lt;!-- To solve faster by saturating multiple CPU cores --&gt;//结果承载类&lt;solutionClass&gt;org.optaplanner.examples.machinereassignment.domain.MachineReassignment&lt;/solutionClass&gt; //结果类&lt;entityClass&gt;org.optaplanner.examples.machinereassignment.domain.MrProcessAssignment&lt;/entityClass&gt; &lt;scoreDirectorFactory&gt; &lt;incrementalScoreCalculatorClass&gt;org.optaplanner.examples.machinereassignment.solver.score.MachineReassignmentIncrementalScoreCalculator&lt;/incrementalScoreCalculatorClass&gt; &lt;!--&lt;scoreDrl&gt;org/optaplanner/examples/machinereassignment/solver/machineReassignmentScoreRules.drl&lt;/scoreDrl&gt;--&gt; &lt;/scoreDirectorFactory&gt; //解法器停下来的规则 &lt;termination&gt; &lt;minutesSpentLimit&gt;5&lt;/minutesSpentLimit&gt; &lt;/termination&gt; //具体使用哪些解法器的计算规则 &lt;constructionHeuristic&gt; &lt;constructionHeuristicType&gt;FIRST_FIT&lt;/constructionHeuristicType&gt; &lt;/constructionHeuristic&gt; //自定义计算阶段 &lt;customPhase&gt; &lt;customPhaseCommandClass&gt;org.optaplanner.examples.machinereassignment.solver.solution.initializer.ToOriginalMachineSolutionInitializer&lt;/customPhaseCommandClass&gt; &lt;/customPhase&gt; //本地搜索计算阶段 &lt;localSearch&gt; &lt;unionMoveSelector&gt; &lt;changeMoveSelector/&gt; &lt;swapMoveSelector/&gt; &lt;/unionMoveSelector&gt; &lt;acceptor&gt; &lt;entityTabuSize&gt;7&lt;/entityTabuSize&gt; &lt;!--&lt;lateAcceptanceSize&gt;2000&lt;/lateAcceptanceSize&gt;--&gt; &lt;/acceptor&gt; &lt;forager&gt; &lt;acceptedCountLimit&gt;2000&lt;/acceptedCountLimit&gt; &lt;!--&lt;acceptedCountLimit&gt;500&lt;/acceptedCountLimit&gt;--&gt; &lt;/forager&gt; &lt;/localSearch&gt;&lt;/solver&gt;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法 解法器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次docker容器频繁oom的问题排查]]></title>
    <url>%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1docker%E5%AE%B9%E5%99%A8%E9%A2%91%E7%B9%81oom%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[业务系统在docker内内存持续增大，导致频繁被系统kill使用 cat /var/log/message 查看kernal日志得到是因为oom被系统kill 使用docker stats 查看容器运行状况 docker run 命令如下(使用了lxcfs，事实证明最后的解决方案并不需要用到lxcfs)1docker run -m 2800M --memory-swap 3500M --memory-swappiness 60 -p 9011:9011 -dit --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --restart=always -e CATALINA_OPTS=&apos;-Xmx200m&apos; --name=$&#123;project&#125; --network=host -v /etc/localtime:/etc/localtime:ro --hostname=alioracle -v logs$&#123;project&#125;:/tools/tomcat8/logs -v /tools/application2.properties:/tools/tomcat8/bin/application.properties $extrarunops scm.nicezhuanye.com:6555/$p:$version` 设置-Xmx200m (使用-swapiness可以决定程序使用交换内存的意愿，0-100，0表示绝对不会使用交换内存，越大使用的概率越大，设置交换内存后，程序把交换内存跑满，一样会被kill) 初步怀疑java heap泄露使用 docker exec -it schedulercore2 bash -c &quot;wget https://alibaba.github.io/arthas/arthas-boot.jar &amp;&amp; java -jar arthas-boot.jar&quot; 进入容器内使用 arthas的dashborad命令查看java heap并没有超过限制 所以有可能是堆外内存超了使用pmap &lt;pid&gt; -X来查看java进程的内存情况 发现很多两个一组，加起来等于65536kb也就是64mb，仔细观察大多都是132kb的堆是rw权限，650000多的是无权限的内存块 使用gbd attach &lt;pid&gt; 到java进程上使用命令 dump memory &lt;path&gt; &lt;start address&gt; &lt;end address&gt;将内存块dump到磁盘上，（例如 dump memory /tools/core.dump 0x7fce18000000 0x7fce18000000+65536，开始地址为pmap中的内存地址直接加0x前缀，结束地址为开始地址加内存块地址长度）使用strings命令查看dump的内容，发现无可查看内容（有可能是无用内存） 查看网上资料，网上也有很多大老遇到了类似的问题http://ju.outofmemory.cn/entry/105474https://blog.csdn.net/ityouknow/article/details/84038718 初步得到可能是glibc内存分配的原因可以添加系统变量MALLOC_ARENA_MAX=4 来限制堆的使用尝试后发现64mb的堆的确少了，但是还是会出现内存爆炸的现象 之后尝试文章中将glibc替换为谷歌研发的tcmalloc后，成功稳定住了堆外内存使用yum install gperftools-libs.x86_64在/usr/lib64中可以找到libtcmalloc.so.4将该文件添加到docker镜像中DOCKERFILE中添加 LD_PRELOAD=&quot;/usr/lib64/libtcmalloc.so.4.1.0&quot; 环境变量 这样就将glibc替换为了tcmalloc]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用lxcfs提高docker容器的资源可见性]]></title>
    <url>%2F%E4%BD%BF%E7%94%A8lxcfs%E6%8F%90%E9%AB%98docker%E5%AE%B9%E5%99%A8%E7%9A%84%E8%B5%84%E6%BA%90%E5%8F%AF%E8%A7%81%E6%80%A7%2F</url>
    <content type="text"><![CDATA[问题docker容器中，使用top,free等名称查看的资源使用情况不是容器自身的资源使用情况，而是宿主机的资源使用情况，这可能会令某些程序中依赖的第三方库运行在容器中时使用相同的渠道读取系统资源情况错误而导致崩溃实际上，容器中使用top,free等命令是从宿主机的123456/proc/cpuinfo/proc/diskstats/proc/meminfo/proc/stat/proc/swaps/proc/uptime 中获取信息 为了避免这种情况，可以使用一个叫做lxcfs的服务提高资源可见性lxcfs是一个常驻服务，它启动以后会在指定目录中自行维护与上面列出的/proc目录中的文件同名的文件，容器从lxcfs维护的/proc文件中读取数据时，得到的是容器的状态数据，而不是整个宿主机的状态。 使用yum安装wget https://copr-be.cloud.fedoraproject.org/results/ganto/lxd/epel-7-x86_64/00486278-lxcfs/lxcfs-2.0.5-3.el7.centos.x86_64.rpm yum install lxcfs-2.0.5-3.el7.centos.x86_64.rpm 启动lxcfs /var/lib/lxcfs &amp; 容器配置docker run命令增加如下参数（可选部分）123456-v /var/lib/lxcfs/proc/cpuinfo:/proc/cpuinfo:rw \-v /var/lib/lxcfs/proc/diskstats:/proc/diskstats:rw \-v /var/lib/lxcfs/proc/meminfo:/proc/meminfo:rw \-v /var/lib/lxcfs/proc/stat:/proc/stat:rw \-v /var/lib/lxcfs/proc/swaps:/proc/swaps:rw \-v /var/lib/lxcfs/proc/uptime:/proc/uptime:rw \ 此时进入容器使用top,free等命令即可看到正常的资源使用情况]]></content>
      <categories>
        <category>docekr</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>lxcfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法题Z字打印（或N字打印）]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%E9%A2%98Z%E5%AD%97%E6%89%93%E5%8D%B0%EF%BC%88%E6%88%96N%E5%AD%97%E6%89%93%E5%8D%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在leetcode刷到一道算法题，比较有意思最后的战绩是这样的执行用时 : 9 ms, 在ZigZag Conversion的Java提交中击败了98.64% 的用户 内存消耗 : 36 MB, 在ZigZag Conversion的Java提交中击败了99.96% 的用户 因为基本用的都是对数组的操作，所以会快一点题目是这样的: 123456789//将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。//输入: s = &quot;LEETCODEISHIRING&quot;, numRows = 4//输出: &quot;LDREOEIIECIHNTSG&quot;//解释:L D RE O E I IE C I H NT S G 实际上就是走龙字形 实现思路就是将原字符串打散成char[]（以下称为原数组)，然后重组这个数组的下标，最后根据重组的下标拼成新的字符串输出我们可以按照上边给出的示例将整个输出拆成相同的单元，如下 1234L D RE O E I IE C I H NT S G 题目中给出的最大行数是4所以，每个单元的最大长度就是4 * 2 - 2，得到公式max = 2n - 2这时再按行来看，第一个单元的第一个字母对应原数组的0下标，第二个单元第一个字母对应0 + max，以此类推，直到下标与max的和大于原数组总长度，这时就该折行了第二行第一个单元第一个字母对应原数组的的第二个下标，也就是1下标，但这时问题来了，第一个单元和第二个单元之间多存在了一个字母O，怎么办呢其实逐行来看，除了第一行和最后一行，每一行的两个单元之间都存在一个字母，这时我们把这个字母左边的空间称为leftSpace右边的空间称为rightSpace，而第一行，特殊的可以看成leftSpace == max, rightSpace == 0,最后一行反之而随着行号的不同，leftSpace以每行2个的速度递减，rightSpace以每行2的速度递增 这时，我们就找到了规律，从第二行开始，这行的所有下标就是从1开始，以leftSpace和rightSpace交替增加得到所有下标 当然第一行我们也可以写成leftSpace和rightSpace交替增加的样子，但是因为第一行rightSpace为0，所以会出现两次相同的结果，这时需要特殊处理下，只记一次 最后贴上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static String convert(String s, int numRows) &#123; //如果行数是1，不需要做转换 if(numRows == 1)&#123; return s; &#125; char[] ss = s.toCharArray(); //字符串总长度 int totalLength = ss.length; //经过转换后的下标顺序 int[] formattedIndex = new int[totalLength]; //每个单元之间间隔字母的左空间长度 int leftSpace = 2 * numRows - 2; //每个单元之间间隔字母的右空间长度 int rightSpace = 0; for(int i = 0, index = 0; i &lt; numRows &amp;&amp; index &lt; totalLength; i++)&#123; int max = i; //用于控制左右空间交替相加的开关 boolean flag = true; //用于比较前后添加的两个下标是否相同，用来处理第一行和最后一行没有间隔字母导致会添加两次相同下标的问题 int lastAdd = i; //每行的开头固定的为（行号-1） formattedIndex[index] = i; index++; //控制每行最大的索引不要超 while(totalLength - 1 &gt;= (flag ? max + (leftSpace - i * 2) : max + (rightSpace + i * 2)))&#123; if(flag)&#123; max = max + (leftSpace - i*2); flag = false; &#125;else&#123; max = max + (rightSpace + i*2); flag = true; &#125; if(max != lastAdd)&#123; formattedIndex[index] = max; index++; lastAdd = max; &#125; &#125; &#125; char[] newChars = new char[totalLength]; for(int i = 0; i &lt; formattedIndex.length; i++)&#123; int index = formattedIndex[i]; newChars[i] = ss[index]; &#125; return new String(newChars); &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些相对实用的IDEA插件]]></title>
    <url>%2F%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%AF%B9%E5%AE%9E%E7%94%A8%E7%9A%84IDEA%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Maven Helper一个很实用的maven插件http://plugins.jetbrains.com/plugin/7179-maven-helper/versions Rainbow Brackets看习惯还好，我看了眼花。。。http://plugins.jetbrains.com/plugin/10080-rainbow-brackets/versions Translation强无敌http://plugins.jetbrains.com/plugin/8579-translation/versions Alibaba Java Coding Guidelines参考意义强大http://plugins.jetbrains.com/plugin/10046-alibaba-java-coding-guidelines/versions lombok（下载时选择对应版本）比较实用的一款getter setting映射插件http://plugins.jetbrains.com/plugin/6317-lombok/versions FindBugs-IDEA只是提供一些建议，有时候还是需要跟着业务走http://plugins.jetbrains.com/plugin/3847-findbugs-idea/versions]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 指南]]></title>
    <url>%2Fdocker-%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[windowsdokcertoolbox就是一个运行着精简的linux的虚拟机，这个虚拟机中跑着docker，就是这样安装好docker tool box后，桌面会多出来3个图标，第一个是命令窗口，第二个是docker虚拟机里面镜像什么的管理界面，第三个是虚拟机的管理（类似于VM虚拟机） dockertoolbox安装过程和问题（必看）https://blog.csdn.net/qq2712193/article/details/54576313（window7下利用DockerToolbox安装Docker）https://blog.csdn.net/qq_33575129/article/details/78196279（使用docker时报错“net/http: TLS handshake timeout”的解决方案） 使用第一个图标，就是终端来链接虚拟机，此时终端输入的命令是在虚拟机内执行的，可以通过如下命令ssh进入虚拟机docker-machine ssh default这个default就是虚拟机的名字也可以通过 docker-machine ls 这条命令来查看当前活跃的虚拟机上述命令是在这个dockertoolbox下才能用的 linuxlinux下使用的centos，可以使用yum来安装dockeryum search dockeryum install &#39;找到的docker的名称&#39;service docker start这样就把docker安装好了 下面的命令是在toolbox或linux下都能用的通用命令docker search &#39;名称&#39; 用来查到docker的镜像docker pull &#39;镜像名称&#39; 拉镜像service docker restart 重启docker服务docker images 已存在的docker镜像docker ps -a 查看docker的所有容器状态docker rm &#39;容器id&#39; 移除容器dokcer rmi &#39;镜像id&#39; 移除镜像（需要注意的是如果要移除镜像，需要先移除使用这个镜像的容器）docker login &#39;url&#39; 登录私服，用户名密码需要私服提供，hqjl的就是jira的账号docker stats 查看容器资源使用情况docker update -m 4096m &#39;容器id&#39; 动态修改容器内存限制docker rm -f &#39;容器id&#39; 强制停止一个容器，然后删除容器 在项目docker目录下执行以下命令来build镜像，保证docker目录下有testserv.war这个文件，原理是把docker文件夹当做container传到服务中去做builddocker build . -t testserv this commad will create a local virtual network for all local docker machinedocker network create -d overlay --attachable testnet this comman will run an image, -it will open a log terminal, –rm means exit image will kill container, –network means use virtual network which previous commad createdocker run -it --rm --name=testserv --network=testnet scm.xxx.com:6555/zookeeper docker run命令后可以指定容器的最大使用内存，最大交换内存，以及使用交换内存的意愿-m 300M --memory-swap=1 --memory-swappiness 60 使用ctrl + p，然后放开p不放开ctrl，再按q可以缩小当前进入的docker容器而不杀掉他use command &#39;docker attach testserv&#39; to reconnect the image enter a console which connect the specify iamge with a new port, -it means use a new portdocker exec -it testserv bash]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java代理模式]]></title>
    <url>%2Fjava%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理代理模式就是使用代理技术动态生成一个类 两种代理方式有两种代理实现，一种是jdk自带的动态代理，另一种是cglib实现的代理 jdk实现的过程是拿到需要实现的接口（可以使多个接口）以及具体的InvocationHandler，然后使用字节码拼成一个全新的类，这个类的内部有接口的所有方法，每个方法的实现相同，都是调用InvocationHandler，jdk的动态代理只能代理接口，不能代理普通类 cglib实现的过程依旧是拿到需要实现的接口（可以使多个接口）或者普通类以及具体的MethodInterceptor ，然后通过字节码拼成一个新的代理类，这个代理类是继承自目标类，然后使用MethodInterceptor复写其中的方法，cglib的代理不仅可以代理接口，还可以代理普通类 代理工作原理代理的对象在使用的时候，无论调用哪个方法，都会调用创建代理类时的那个InvocationHandler，其中三个参数proxy就是代理的对象，一般很少用到，method的调用的方法信息，args是传入的参数 代理具体用途目前加过的食用方法有两种，一种是xxl的使用方法，InvocationHandler的实现为拿到方法信息后使用HttpClient发送至远端，实现RPC，第二种是像spring的通知一样，代理一个对象，比如前置通知，InvocationHandler的实现就是两步，第一步先调用你的通知方法，第二步调用目标类的方法 spring如何选择代理spring会动态的选择代理的类型，当目标类有实现接口，那就使用jdk的方式，只是普通类的话就使用cglib]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle遇到的坑]]></title>
    <url>%2Foracle%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[1.jpa如果打开spring.jpa.hibernate.ddl-auto=update的话，会把给定长度比较长的字段更新为LONG类型，但是LONG类型在oracle中，一张表只能存在一个列解决办法就是手动把列类型修改成CLOB，或者使用flyway 2.jpa在做update的时候，如果报错ORA-22295: 不能把超过 4000 字节数据绑定到语句 1 中的 LOB 和 LONG就是说不能同时update一张表中的LONG类型和BLOB/CLOB类型解决办法是同一条sql，或者jpa的save中，只update一个LONG字段，或者多个BLOB/CLOB字段 3.如果报错ORA-01502: 索引 &#39;TEST0709.SYS_C0011897&#39; 或这类索引的分区处于不可用状态解决办法是使用查询select * from user_indexes where status &lt;&gt; &#39;VALID&#39;;查询到所有失效的索引，然后通过下面语句（替换要重建的索引名）来重建索引alter index index_name rebuild;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三种启发式算法的意义]]></title>
    <url>%2F%E4%B8%89%E7%A7%8D%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95%E7%9A%84%E6%84%8F%E4%B9%89%2F</url>
    <content type="text"><![CDATA[Constructive heuristic构造性启发式是一种启发式方法，它以空解决方案开始，并重复扩展当前解决方案，直到获得完整的解决方案。它与本地搜索启发式不同，后者以完整的解决方案开始，然后尝试通过本地移动进一步改进当前的解决方案 metaheuristic有别于heuristic的一种方法，他是一种更通用的算法，也属于heuristic Partitioned SearchPartitioned Search是一个可以进行分片计算的算法，在大规模计算中，可以将模型分割成多个区域，利用多核cpu进行运算，之后再拼成一个完整的解，即使cpu只有一个核，通常也比其他算法快，但是通过这种算法有可能得到的解不如只利用heuristic得到的解分数高]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot 特别功能]]></title>
    <url>%2Fspringboot-%E7%89%B9%E5%88%AB%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[springboot可以指定外部配置文件如果使用jar包启动，需要将配置文件放在和jar包同级的config文件夹下，如果在jar包内没有指定启动的配置文件名称，则config文件夹下的配置文件名必须为application.properties。如果使用tomcat启动springboot，则在tomcat的lib目录下新建config目录，操作步骤同上。springboot中可以指定激活多个配置文件，spring.profiles.active=dev,prod，像这样使用逗号配置文件名隔开即可。 springboot 配置文件外置当然，还有一种可以读取配置文件的地方，就是启动应用的地方(启动tomcat时，你当前所在的目录，可以通过pwd看在哪里，如果配置文件在bin目录，然后通过脚本启动，必须先cd到bin目录，再执行启动)，将配置文件名固定为application.properties，可以将其中的内容覆盖至webapps下面启动的springboot项目中的配置文件，只有项目中的配置文件没有使用spring.profiles.active指定配置文件或仅指定default时生效，指定后，启动应用的地方的配置文件就不能生效了，需要注意的是，这种方式启动的tomcat是将这个配置文件共享的，包括由tomcat内springboot项目使用java -jar启动的应用都会受到这个配置文件的影响]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flyway]]></title>
    <url>%2Fflyway%2F</url>
    <content type="text"><![CDATA[flyway用于数据库脚本升级的管理工具 flyway在第一次使用的时候需要一个元数据表，叫做schema_version. 用来记录数据库迁移（或者更新的历史），这张表不需要手动建立，flyway会自己生成这张表，但是需要注意的是，这张表的首行必须是一条baseline，就像这样一样 这行可以在springboot的配置文件中加入，就像这样 它是一个基行，从他开始记录 表中version字段为主键。约定大于配置，在flyway中，有好几种数据库升级的方式，可以使用sql脚本，也可以使用java的方式，约定java类用这样的方式命名，最后会被flyway解析成3.11就像第一张图的样子，类或者sql脚本放在scr/main/java/db/migration文件夹下，这是约定 12345(maven依赖)&lt;dependency&gt; &lt;groupId&gt;org.flywaydb&lt;/groupId&gt; &lt;artifactId&gt;flyway-core&lt;/artifactId&gt;&lt;/dependency&gt; 在springboot中，可以在类中实现SpringJdbcMigration来当做升级脚本使用 类似于这样，实现的方法中的参数jdbcTemplate会由spring注入，使用jdbcTemplate操作数据库 使用：按照上述写好后，启动springboot的过程中会自动扫描schema表和db/migration下的版本脚本，并且执行相关脚本 注意：flyway会按照版本号递增来执行脚本，比如文件夹下脚本有v1.1和v.12两个，SCHEMA表中只存在v1.1，那么flyway只会执行v1.2但是，如果SCHEMA表中有v1.2却没有v1.1，那么程序启动会报错]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>flyway</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java hotspot版本虚拟机垃圾回收机制]]></title>
    <url>%2Fhotspot%E7%89%88%E6%9C%AC%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[首先，堆中的内存分为三个大块(java8是两个，持久代被干掉了)，新生代和老年代，持久代，新生代为各种new出来的对象所在场所，老年代存放的是在多次GC都活下来的对象，持久代（也被称作方法区，存放各种静态文件，包括类，方法等）不会发生minor GC，当持久代满时，会触发full GC java8中，持久代被替换成metaspcace，metaspace不会占用虚拟机内存，占用的是本地内存 (1.7及1.7之前的版本持久代存放的是对象的方法等信息，持久代是占用堆内存的，1.8之后转移到了metaspace，metaspace占用的是本地内存，不会占用堆内存，类的元数据信息转移到Metaspace的原因是PermGen很难调整。PermGen中类的元数据信息在每次FullGC的时候可能会被收集，但成绩很难令人满意。而且应该为PermGen分配多大的空间很难确定，因为PermSize的大小依赖于很多因素，比如JVM加载的class的总数，常量池的大小，方法的大小等) 新生代分为三个区域，eden(伊甸园)，两个survivor区 老年代大多都是由标记整理，标记清除来整理空间 新生代比较有意思，他由于存放的一般都是比较新的对象，但一般对象的生命周期比较短，所以需要比较频繁的GC，但是呢，GC线程一启动，就会暂停其他线程，stop the world，所以就会有一个minior GC，来清理新生代 清理新生代使用的是复制算法，所有的新对象被生成在eden区，当eden区容量不够时，会触发minor GC，两个survivor区被分为From 和 To 区，触发minior GC时，eden区存活的大对象直接转移至老年代，不可达对象被直接清理，eden区剩余存活对象被转移至To区，From区存活的对象分两种情况，活过指定次数（可以设置）GC的对象会被转移到老年代，剩余存活对象也被转移到To区，minior GC结束时，From区是空的，下次执行minor GC时，From区和To区会互换身份 也就是说，每次minior GC结束后，总是有一个区是空的 需要注意的是，在minior GC过程中，如果To区满了，那么剩余本来会转移到To区的对象会被直接移到老年代，无论是否活过了指定次数的GC 而触发full GC的条件，就是年老代满时，或者方法区满时，或者调用System.gc（然而只是系统建议，并不一定会执行）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java ClassLoader 解读]]></title>
    <url>%2Fjava-ClassLoader-%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[classLoader类加载器双亲委托，MyClassLoader -&gt; AppClassLoader -&gt; ExtClassLoader -&gt; BootStrapClassLoader首先MyClassLoader 在加载一个类的时候会先去自己已加载的类中去找，如果没有找见就去他的上级AppClassLoader 类中找，AppClassLoader 也没加载过的话就去ExtClassLoader 中找，以此类推，直到BootStrapClassLoader也发现没有加载，这个时候MyClassLoader 才会尝试自己加载，这是为了防止重复加载一个类的机制。 ClassLoader.getSystemClassLoader()这个方法会返回AppClassLoaderThread.currentThread(),getContextClassLoader这个方法在IDEA以Application启动时会返回AppClassLoader，而以springboot启动时会返回springboot自己的classLoader，也就是LaunchedURLClassLoader，两者在IDEA中跑代码没有问题，但是在jar包启动的时候，AppClassLoader加载的url只有一个，而LaunchedURLClassLoader是以jar in jar的方式加载的，如下图 这个问题会导致一些自定义的URLClassLoader加载不到类，自定义URLClassLoader如果不指定父加载器的话默认是AppClassLoader，这个时候使用URLClassLoader会导致某些类加载不上，解决这个问题需要指定URLClassLoader的父加载器， 1URLClassLoader urlClassLoader = new URLClassLoader(new URL[]&#123;url&#125;, Thread.currentThread().getContextClassLoader()) 使用Thread.currentThread().getContextClassLoader()即可参考文章:http://blog.csdn.net/hengyunabc/article/details/77413669 （深入Spring Boot：ClassLoader的继承关系和影响）http://blog.csdn.net/peter_k/article/details/1667685 (Thread.getContextClassLoader() 祥解, 详细解释了系统对于classLoader的选择)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring data jpa 遇到的坑]]></title>
    <url>%2Fspring-data-jpa-%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[更新了你不想更新的实例首先findOne()方法找到一个实体，暂且叫A，实体包含Id属性和一个引用类型的数据然后new一个这个实体，叫B，将那个引用类型稍作修改后set到B中save()这个实体B 理想情况是B作为一个新的记录被插入到数据库，这个没问题，但是A在这次save()中那个引用类型也被保存了，问题是并没有save()实体A 实际上，这是由于查出来的实体是一个有entityManager管理的托管状态的一个实体，他的属性在变化后hibernate是知道的，在默认情况下调用了save()等方法后，由于事务的提交，一并将A的改变提交了 解决办法可以通过entityManager的clear()方法，来将托管状态的实体清除，接下来的事务提交不会提交被清除的实体，如果使用的是CURDRepositry或JPARepositry等，可以通过一下办法调用entitymanager 他会清除当前session所保存的实体 在同一个方法内（或者说是同一个session内），期望多次通过findOne来拿到最新的实体，但发现只有第一次会发送sql语句，后来的只会从一级缓存拿与上面的类似，可以通过在findOne之后clear()来解决问题，因为hibernate会先去一级缓存中找实体，如果没有，就在数据库中找，所以当你的代码第一次查时会放到一级缓存中，导致后续的查找都从一级缓存中查 （这个方法暂时有问题）还有另一种方式就是不要写那么多findOne()，找到一次后，使用entityManager的refresh()方法来刷新这个实体，可以达到一样的效果(好像发出了sql，但是没有更新实体) springboot中，如果同时使用JPA或flyway可能会遇到的问题如果开启了jpa，并且application.properties中配置了如下语句12#jpa自动根据实体类更新表结构spring.jpa.hibernate.ddl-auto=update 并且又配置了flyway那么springboot启动的时候，会先跑flyway，后跑JPA]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stream的forEach与传统for循环效率]]></title>
    <url>%2Fstream%E7%9A%84forEach%E4%B8%8E%E4%BC%A0%E7%BB%9Ffor%E5%BE%AA%E7%8E%AF%E6%95%88%E7%8E%87%2F</url>
    <content type="text"><![CDATA[结论就是 传统for循环在效率上会比stream高，但是两者差别不大 注重性能可以使用for循环注重开发效率和可维护性可以选择stream，可以牺牲一点代码运行效率来换取开发效率]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows部分cmd命令(shell脚本)]]></title>
    <url>%2Fwindows%E9%83%A8%E5%88%86cmd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cmd命令/bat set title=tomcat使用set来定义变量，使用%tile%来读取变量，例如echo %title%call命令可以在一个bat中调用另一个bat，并且子bat的结束并不会导致调用它的bat结束start cmd 可以以一个新的窗口启动命令，start cmd /c 为在新窗口执行完后关闭，start cmd /k 相反，start cmd后如果需要指定多条命令，可以使用&amp;&amp;将多条命令连接echo.为显示回车 if exist c:\temp\a.txt( echo &quot;exist&quot; ) else ( &quot;echo not exsit&quot; ) 这样写if语句，可以使用exsit或者not exist taskkill /F 是强制，/FI 是搜索, /T是结束该进程和相关的子进程，例如taskkill /F /T /FI &quot;WINDOWTITLE eq tomcat&quot; 在脚本后增加pause命令，可以使脚本运行窗口停留在pause的位置，方便观察报错信息 netstat -ano | findstr 端口号可以找见端口号对应的记录，记录的最后一行为pidnetstat -ano | findstr 8011]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>cmd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux设置ftp服务]]></title>
    <url>%2Flinux%E8%AE%BE%E7%BD%AEftp%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[安装vsftpd12345678#安装vsftpdyum install -y vsftpd#设置开机启动systemctl enable vsftpd.service # 重启service vsftpd restart# 查看vsftpd服务的状态systemctl status vsftpd.service 配置vsftpd.conf12345678910111213141516171819#备份配置文件 cp /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.bak#执行以下命令sed -i &quot;s/anonymous_enable=YES/anonymous_enable=NO/g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos;sed -i &quot;s/#anon_upload_enable=YES/anon_upload_enable=NO/g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos;sed -i &quot;s/#anon_mkdir_write_enable=YES/anon_mkdir_write_enable=YES/g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos;sed -i &quot;s/#chown_uploads=YES/chown_uploads=NO/g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos;sed -i &quot;s/#async_abor_enable=YES/async_abor_enable=YES/g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos;sed -i &quot;s/#ascii_upload_enable=YES/ascii_upload_enable=YES/g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos;sed -i &quot;s/#ascii_download_enable=YES/ascii_download_enable=YES/g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos;sed -i &quot;s/#ftpd_banner=Welcome to blah FTP service./ftpd_banner=Welcome to FTP service./g&quot; &apos;/etc/vsftpd/vsftpd.conf&apos; 1234567891011121314#添加下列内容到vsftpd.conf末尾use_localtime=YESlisten_port=21chroot_local_user=YESidle_session_timeout=300guest_enable=YESguest_username=vsftpduser_config_dir=/etc/vsftpd/vconfdata_connection_timeout=1virtual_use_local_privs=YESpasv_min_port=10060pasv_max_port=10090accept_timeout=5connect_timeout=1 建立用户文件123456#第一行用户名，第二行密码，不能使用root为用户名vi /etc/vsftpd/virtuserschris123456chang123456 生成用户数据文件12345db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db#设定PAM验证文件，并指定对虚拟用户数据库文件进行读取chmod 600 /etc/vsftpd/virtusers.db 修改/etc/pam.d/vsftpd文件123456789101112# 修改前先备份 cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.bak# 将auth及account的所有配置行均注释掉vi /etc/pam.d/vsftpdauth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusersaccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusers# 如果系统为32位，上面改为lib 新建系统用户vsftpd，用户目录为/home/vsftpd123#用户登录终端设为/bin/false(即：使之不能登录系统)useradd vsftpd -d /home/vsftpd -s /bin/falsechown -R vsftpd:vsftpd /home/vsftpd 建立虚拟用户个人配置文件123456789101112131415161718mkdir /etc/vsftpd/vconfcd /etc/vsftpd/vconf#这里建立两个虚拟用户配合文件touch chris chang#建立用户根目录mkdir -p /home/vsftpd/chris/#编辑chris用户配置文件，内容如下，其他用户类似vi chrislocal_root=/home/vsftpd/chris/write_enable=YESanon_world_readable_only=NOanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES 防火墙设置123vi /etc/sysconfig/iptables#编辑iptables文件，添加如下内容，开启21端口-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT 重启vsftpd服务器12345service vsftpd restart如果只能上传不能下载，先去/home/vsftp(就是你的ftp上传文件的目录)将用户组root改为vsftpd，权限a-w，然后#vi /etc/vsftpd.conf （或者是在/etc/vsftpd/vsftpd.conf，总之知道自己服务器的配置文件）添加 allow_writeable_chroot=YES]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven使用插件利用json生成javabean]]></title>
    <url>%2Fmaven%E4%BD%BF%E7%94%A8%E6%8F%92%E4%BB%B6%E5%88%A9%E7%94%A8json%E7%94%9F%E6%88%90javabean%2F</url>
    <content type="text"><![CDATA[使用如下样例代码，注意json文件位置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;plugin&gt; &lt;groupId&gt;org.jsonschema2pojo&lt;/groupId&gt; &lt;artifactId&gt;jsonschema2pojo-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.30&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;execution1&lt;/id&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;configuration&gt; &lt;sourcePaths&gt; &lt;sourcePath&gt;$&#123;basedir&#125;/schema/settings.json&lt;/sourcePath&gt; &lt;sourcePath&gt;$&#123;basedir&#125;/schema/stuStaticInfos.json&lt;/sourcePath&gt; &lt;sourcePath&gt;$&#123;basedir&#125;/schema/gradeInfo.json&lt;/sourcePath&gt; &lt;/sourcePaths&gt; &lt;targetPackage&gt;com.hqjl.classify.input.model&lt;/targetPackage&gt; &lt;sourceType&gt;json&lt;/sourceType&gt; &lt;serializable&gt;false&lt;/serializable&gt; &lt;classNameSuffix&gt;Model&lt;/classNameSuffix&gt; &lt;generateBuilders&gt;true&lt;/generateBuilders&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;execution2&lt;/id&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;configuration&gt; &lt;sourcePaths&gt; &lt;sourcePath&gt;$&#123;basedir&#125;/schema/results.json&lt;/sourcePath&gt; &lt;/sourcePaths&gt; &lt;targetPackage&gt;com.hqjl.classify.result.model&lt;/targetPackage&gt; &lt;sourceType&gt;json&lt;/sourceType&gt; &lt;serializable&gt;false&lt;/serializable&gt; &lt;classNameSuffix&gt;Model&lt;/classNameSuffix&gt; &lt;generateBuilders&gt;true&lt;/generateBuilders&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;execution3&lt;/id&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;configuration&gt; &lt;sourcePaths&gt; &lt;sourcePath&gt;$&#123;basedir&#125;/schema/actionId.json&lt;/sourcePath&gt; &lt;/sourcePaths&gt; &lt;targetPackage&gt;com.hqjl.classify.request&lt;/targetPackage&gt; &lt;sourceType&gt;json&lt;/sourceType&gt; &lt;serializable&gt;false&lt;/serializable&gt; &lt;classNameSuffix&gt;Model&lt;/classNameSuffix&gt; &lt;generateBuilders&gt;true&lt;/generateBuilders&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react编译]]></title>
    <url>%2Freact%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[编译项目下的页面 在命令窗口中使用 npm install -g cnpm --registry=https://registry.npm.taobao.org 命令来下载淘宝镜像的node_modules缓存（暂时这样理解），之后进入所需目录执行 cnpm install 来安装依赖模块node_modules，node_modules可能根据不同路径大小不一样，依赖包安装好后使用 webpack -d （也有可能使用 npm run dev 命令来编译，具体情况可以询问）命令来编译文件，最后生成编译后的的dist文件夹 webcontent目录可能需要node_modules依赖模，其他子系统如plantformmanager文件夹下依次生成node_modules模块和编译dist文件夹，那个模块需要使用，就编译哪个模块，每个模块都需要node_modules和dist文件夹，webcontent目录可能不管如何都需要node_modules]]></content>
      <categories>
        <category>react</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat8启用gzip压缩]]></title>
    <url>%2Ftomcat8%E5%90%AF%E7%94%A8gzip%E5%8E%8B%E7%BC%A9%2F</url>
    <content type="text"><![CDATA[方法非常简单，只需要在Connector节点中加入以下内容即可： 12345useSendfile=&quot;false&quot;compression=&quot;on&quot; compressionMinSize=&quot;50&quot; noCompressionUserAgents=&quot;gozilla, traviata&quot; compressableMimeType=&quot;text/html,text/xml,text/javascript,text/css,text/plain,application/javascript,application/x-javascript&quot;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识rest风格api]]></title>
    <url>%2F%E5%88%9D%E8%AF%86rest%E9%A3%8E%E6%A0%BCapi%2F</url>
    <content type="text"><![CDATA[本着对rest的学习，记录下学习的心得。 首先什么是rest用我的话说就是他是一个无状态的url或者说是uri对应服务器上的一个资源，使用http的post（增），delete（删），put（改），get（查）来标记请求的动作。再简单点就是用url来标记资源位置，用http来描述动作。 样例服务器中可以用springMVC的注解@pathVariable来获得url的资源位置，例如http://example/v1/user/123中，可以使用@pathVariable来获得123这个标记，在springMVC的@requestMapping注解中除了使用value属性来映射请求地之外，可以加上method属性来标记这个方法对应http请求的哪种操作。例如： 123456789101112131415161718@Controller@RequestMapping(&quot;rest&quot;)public class Rest &#123; @RequestMapping(value=&quot;source&quot;,method=RequestMethod.PUT) @ResponseBody public String sourcePut()&#123; String msg = &quot;this is put&quot;; return msg; &#125; @RequestMapping(value=&quot;source&quot;,method=RequestMethod.POST) @ResponseBody public String sourcesPost()&#123; String msg = &quot;this is post&quot;; return msg; &#125;&#125; 在这段代码中，如果请求地址为http://example/rest/source，使用put发送请求，那么最终执行到的是sourcePut这个方法，如果使用post发送请求，那么最终执行到的是sourcePost这个方法。 上边是比较简单的实现方式，对于rest，还可以举出两个例子来说明什么是rest 第一个例子，客户端如果在阅读有分页的文章，那么他向服务器发送的的请求为“我想查看下一页”，然后服务器返回下一页，客户端再次发送“我想查看下一页”，服务器依然会执行下一页，在这个例子中，服务器是保存客户端状态的，这不是rest，rest的服务器是不会保存用户状态的，也就是说，服务器是不会相应“我想查看下一页”这种请求的，客户端需要自己去维护状态，并向服务器发送资源地址去请求下一页。 第二个例子是在人员管理系统中，如果想获得张三的工资，必须先登录系统，点击个人，再点击工资查询，才能获得张三的工资，那么，如果其中缺啥一步，就不能获得张三的工资，也就是说，没有一个唯一的资源路径能够直接获得张三的工资，而rest的接口，直接会给定一个路径去访问张三的工资（暂时可以这么说，其他方面暂不考率）。 通过上边两个例子，可以大致了解rest的含义，使用rest也会好处，系统扩展性会强，由于使用的是资源地址，如果浏览器允许缓存的话，可以直接加载缓存，不用再访问服务器了。 参考资料：https://www.zhihu.com/question/28557115 （这是一个知乎问题，里面的回答都很受用）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下使用jstack打印当前时间线程的快照及使用命令查看指定端口的情况]]></title>
    <url>%2Fwindows%E4%B8%8B%E4%BD%BF%E7%94%A8jstack%E6%89%93%E5%8D%B0%E5%BD%93%E5%89%8D%E6%97%B6%E9%97%B4%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%BF%AB%E7%85%A7%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E6%9F%A5%E7%9C%8B%E6%8C%87%E5%AE%9A%E7%AB%AF%E5%8F%A3%E7%9A%84%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[一.windows下使用jstack打印当前时间线程的快照在cmd中使用 jstack -l 线程号 来打印 例如在任务管理器中获得的线程号为1548的线程，可在cmd中输入 jstack -l 1548 来打印当前线程快照 二.使用命令查看指定端口的情况在cmd中输入 netstat -an | findstr 端口号即可查看该端口的状态 例如端口为8081，在cmd中输入 netstat -an | findstr 8081 即可查看]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决springMVC中@response向前台传递参数变问号的问题]]></title>
    <url>%2F%E8%A7%A3%E5%86%B3springMVC%E4%B8%AD-response%E5%90%91%E5%89%8D%E5%8F%B0%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0%E5%8F%98%E9%97%AE%E5%8F%B7%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[转自 http://m.blog.csdn.net/article/details?id=52097745 感谢原作者 SpringMVC的@ResponseBody返回中文乱码的原因是SpringMVC默认处理的字符集是ISO-8859-1，在Spring的org.springframework.http.converter.StringHttpMessageConverter类中可以看到如下代码： 12public static final Charset DEFAULT_CHARSET = Charset.forName(&quot;ISO-8859-1&quot;);static final Charset DEFAULT_CHARSET = Charset.forName(&quot;ISO-8859-1&quot;); 解决返回中文乱码的问题有两种，第一种是局部的，只针对于某个方法的返回进行处理，第二种是全局的，针对于整个项目，如下： 第一种：在@RequestMapping中添加produces=&quot;text/html;charset=UTF-8，如：12345@RequestMapping(value=&quot;/login.do&quot;,method=RequestMethod.POST,produces=&quot;text/html;charset=UTF-8&quot;) @ResponseBody public String login(@RequestParam(value=&quot;username&quot;) String userName,@RequestParam(value=&quot;password&quot;) String password)&#123; return JSONMessageUtil.getSuccessJSON(&quot;登录成功&quot;); &#125; 第二种：在配置文件中的mvc:annotation-driven中添加如下代码：12345678&lt;mvc:annotation-driven &gt; &lt;!-- 消息转换器 --&gt; &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot; value=&quot;text/html;charset=UTF-8&quot;/&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 对于乱码问题，这样就可以正常显示中文了]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于集群与分布式及正向代理与反向代理的初步总结]]></title>
    <url>%2F%E5%85%B3%E4%BA%8E%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E5%88%9D%E6%AD%A5%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[集群与分布式集群就是多台计算机进行连接，每台计算机上部署的应用是一致的，集群的目的是提高整个系统的高并发时的稳定性，当有一台服务器挂掉时，其他的服务器可以顶上来，不会出现服务器挂掉后整个网站崩溃的情况。 分布式是由多个计算机组成的系统，每台计算机运行整个系统中一个模块，分布式提高了系统处理数据的效率。 集群与分布式的区别可以用以下例子区别： 假如有一个任务有10个子任务，每个子任务需要花1个小时处理完成，去过使用分布式系统，在10台计算机上分别部署这10个子任务，那么完成一个任务的时间为1小时。当使用几群的时候，10台计算机由于部署的任务一致，不管请求最终分发到哪台服务器上，完成的时间都为10小时。 用这两种方式的利弊在于在效率与稳定性上边做取舍。 正向代理与反向代理正向代理类似于科学上网，假如你要上谷歌，请求直接发到谷歌服务器会直接被屏蔽掉，但是如果你在国外安置一台服务器，你的请求发到这台服务器，再由这台服务器转发至谷歌，那么你的目的就达到了。这台在国外的服务器就是正向代理的服务器。客户端知道要访问的服务器是哪个，但服务器不知道客户端是哪个，这就是正向代理。 反向代理类似于你访问百度，百度官网只不过是一个代理服务器，你不知道你的请求由百度那么多服务器中哪台服务器处理了，你的请求由那台服务器转发至代理服务器认为比较合适的服务器来处理。客户端不知道目标服务器，由代理服务器转发请求，这就是反向代理。 注：反向代理服务器中比较有名的是Nginx服务器，它是由俄罗斯人开发的，在处理高并发的时候十分有效，可以自动分发请求，也可以自动检测到服务器的状态。并且Nginx可以作为文件服务器来使用。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RestTemplate使用小结]]></title>
    <url>%2FRestTemplate%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本文目的在于记录使用spring集成的resttemplate时的心得。 1.使用模版模拟form表单发送普通数据或发送带有文件的数据 123456789101112private static final String URL = &quot;http://127.0.0.1:8080/test_api/v1&quot;; public String insertCompPic(String userId) &#123; RestTemplate rt = new RestTemplate(); MultiValueMap&lt;String, Object&gt; map = new LinkedMultiValueMap&lt;String, Object&gt;(); map.add(&quot;user_id&quot;, userId); map.add(&quot;title&quot;, &quot;测试标题&quot;); map.add(&quot;grade&quot;, &quot;027023&quot;); File f = new File(&quot;F:\\server\\testPic\\1.png&quot;);FileSystemResource resource = new FileSystemResource(f); map.add(&quot;files&quot;, resource); return rt.postForObject(URL + &quot;/composionedit/subpic&quot;, map, JSONObject.class).getString(&quot;comp_id&quot;);&#125; 其中postForObject中url对应发送请求的地址，map为请求体（这样说很不规范），剩下的一个参数为该接口返回的对象类型。注：可以参考 http://blog.csdn.net/mhmyqn/article/details/26395743 中文件上传的写法，很具体，感谢原作者。 2.模版的exchange方法可以理解为一个通用的请求发送器，可以实现put,post,delete等请求，需要在exchange方法中传入必要的参数来确定他所要实现的功能。 3.模版的getForObject方法应为没有表单参数，所以传参时有两种方法，一种是在url中后边加？来拼接get方法所要传递的参数，另一种使用resetful风格的url，例如：1234Map&lt;String, String&gt; vars = new HashMap&lt;String, String&gt;();vars.put(&quot;hotel&quot;, &quot;42&quot;);vars.put(&quot;booking&quot;, &quot;21&quot;);String result = restTemplate.getForObject(&quot;http://example.com/hotels/&#123;hotel&#125;/bookings/&#123;booking&#125;&quot;, String.class, vars); 会转换为一个对http://example.com/hotels/42/rooms/41的GET请求。 （摘自http://blog.csdn.net/z69183787/article/details/41681101，这篇博客里也提供了非常多关于springMVC的rest方面的知识，非常值得一看，同样感谢原作者）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RestTemplate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用maven搭建一套web]]></title>
    <url>%2F%E4%BD%BF%E7%94%A8maven%E6%90%AD%E5%BB%BA%E4%B8%80%E5%A5%97web%2F</url>
    <content type="text"><![CDATA[1.按照正常程序创建maven项目 可参考一下博客：http://www.cnblogs.com/noteless/p/5213075.html （作者noteless） 2.搭建好后会出现的问题有index.jsp会报错，在pom.xml中添加依赖12345&lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt;&lt;/dependency&gt; 即可消除报错 3.之后首要事情改变项目编码为utf-8 4.最大问题在于改变项目的dynamic web model从2.3改变不成3.0，可以按照第一步的博客解决 5.项目在maven update project的时候会出现jre版本降回1.5的情况，可以在pom.xml中build中加入 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; 来解决maven update project的问题 最后十分感谢noteless的博客的帮助，十分感谢]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>web应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于url传参乱码的解决]]></title>
    <url>%2F%E5%85%B3%E4%BA%8Eurl%E4%BC%A0%E5%8F%82%E4%B9%B1%E7%A0%81%E7%9A%84%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[在实际开发过程中，有很多情况会出现传中文参数会乱码的问题，实际上解决乱码参数就是将ISO-8859-1的字符编码转变成utf-8的字符编码（至少我是这样做的）。 以下是字符转码的片段，可作为一个类的工具使用。 12345678910111213141516//转换字符串方法public static String encode(String target)&#123; //定义临时Stirng参数 String tempTarget = null; //当传入参数不为空时，执行if中的代码 if(StringUtils.isNotEmpty(target))&#123; try &#123; //转换格式 tempTarget = new String(target.getBytes(&quot;ISO-8859-1&quot;),&quot;UTF-8&quot;); &#125; catch (UnsupportedEncodingException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; return tempTarget;&#125; 之后是一个字符编码的过滤器。 1234567891011121314151617181920212223public class CharactorFilter implements Filter &#123; //继承Filter类 //字符编码 String encoding=null; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; if(encoding!=null)&#123; //设置request字符编码 request.setCharacterEncoding(encoding); //设置response字符编码 response.setContentType(&quot;text/html;charset=&quot;+encoding); &#125; //传递给下一个过滤器 chain.doFilter(request, response); &#125; public void init(FilterConfig filterConfig) throws ServletException &#123; //获取初始化参数 encoding=filterConfig.getInitParameter(&quot;encoding&quot;); &#125; public void destroy() &#123; // TODO Auto-generated method stub encoding=null; &#125;&#125; 当然不用也行，可以在servlet中设置 123request.setCharacterEncoding(&quot;utf-8&quot;);response.setCharacterEncoding(&quot;utf-8&quot;);response.setContentType(&quot;text/html;charset=utf-8&quot;) 需要注意的是，后两种方法仅对post有效，第一种可对get有效。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>web应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[站点SEO优化]]></title>
    <url>%2F%E7%AB%99%E7%82%B9seo%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[创建sitemap 使用命令 npm i hexo-generator-sitemap hexo-generator-baidu-sitemap -S 来安装两个插件 当你在 hexo g 时,会在public文件夹中生成sitemap.xml 和baidusitemap.xml 一个给自己用，一个给百度用 创建robots 在post文件夹创建robots.txt，内容如下 1234567891011User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /about/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/ 这样可以告诉搜索引擎的爬虫，哪些地址不需要爬取 向百度申请收录链接 直接在百度搜索 site: 你的地址，像我的 site: blog.maxisvest.com 显示没有搜索结果，就说明百度还没有收录这个站点，可以登录百度站长提交你的网站按照百度提供的步骤来验证你提交的地址是否成功 之后使用插件在deploy时向百度提交链接，步骤如下需要先安装插件 npm i hexo-baidu-url-submit -S然后再在站点配置文件中按如下方式新增字段 12345baidu_url_submit: count: 10 # 提交最新的链接数 host: crowncj.com # 在百度站长平台中注册的域名,虽然官方推荐要带有 www, 但可以不带. token: XXXXX # 你的秘钥,每个人都不一样,获取方法在下面 path: baidu_urls.txt # 文本文档的地址,新链接会保存在此文本文档里 然后在站点配置文件中修改如下，注意格式缩进 123456deploy: - type: git repo: https://xxx/xxx/xxx.git branch: xxx message: deploy the pages - type: baidu_url_submitter 之后当你执行hexo d的时候会推送新的链接 优化URL，简化文章地址，方便爬虫爬取可以在站点配置中将默认的permalink: :year/:month/:day/:title/修改为permalink: :title/ 启动百度访问量分析 这个并不会提高你的排名，他能帮到你的是，让你心里对你网站的访问量有点B数 登录百度统计，按照提示获得脚本id(就是hm.js?后面的id)在next主题的baidu_analytics属性后填写id，就可以了 另外可以在微信公众号中实时关注你网站的统计 在站点配置文件中设置keywords类似于keywords: maxisvest,java,技术，用逗号隔开，这样有利于搜索另外，文章中的tags标记，会在生成文章时变为文章header中的keywords关键字]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo常用命令]]></title>
    <url>%2Fhexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[常用命令1.异地拉取仓库代码由于仓库内没有module资源，所以需要本地npm install安装依赖 2.进入项目根目录可以使用hexo命令 hexo clean 清除public，就是发布的文件夹 hexo generate 静态化资源，可以简写 hexo g hexo server 本地预览页面，可以简写 hexo s hexo deploy 根据配置将本地静态化页面发布到远端，可以简写 hexo d 3.可以使用 hexo clean | hexo g | hexo s 一串命令来执行一套流程操作 4.使用hexo new page &#39;tags&#39;创建标签索引页，创建后修改index.md内部为（记得去掉其中的括号）12345---title: tagsdate: 2019-01-17 22:57:12type: tags---然后在next的主题配置中打开tags: /tags/ || tags即可 5.创建简单的文章，直接输入hexo new page 文章名即可，hexo会在source目录下创建你文章名的.md文件 注意事项有些改动不需要使用hexo g等命令，在不关闭服务的情况下，比如修改背景图片，yml配置文件等可以不重新启动服务]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo建站指南]]></title>
    <url>%2Fhexo%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[1.使用coding新建仓库，创建git项目，项目创建时必须在初始化时选择空，也就是README，.gitingnore这些都不创建 2.打开pages服务，选择默认分支应该为master或者一个叫做coding-pages的分支，只能这两个名字 3.进入hexo官网，按照官网的教程初始化 4.将整个hexo的项目上传至git，并且添加.gitignore文件，忽略node_modules和public文件夹 5.建议将hexo写作项目上传至master分支，hexo deploy的博客上传至coding-pages分支 6.另外注意，在yml配置文件的每一个配置项的冒号后面，一定要跟一个空格，不然不生效 7.在hexo中实现本地搜索功能（hexo-generator-searchdb）安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： 12345search: path: search.xml field: post format: html limit: 10000]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
